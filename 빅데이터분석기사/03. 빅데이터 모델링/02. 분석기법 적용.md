# 분석기법 적용

## SECTION 01. 분석기법

### 01. 분석기법 개요

1) 학습 유형에 따른 데이터 분석 모델

### 02. 데이터 분석 기획

1) 데이터 분석 기획

- 분석 기획은 실제 분석을 수행하기에 앞서 분석을 수행할 과제의 정의 및 의도했던 결과를 도출할 수 있도록 이를 적절하게 관리할 수 있는 방안을 사전에 계획하는 작업
- 어떠한 목표를 달성하기 위해 어떠한 데이터를 가지고 어떤 방식으로 수행할 것인가에 대한 일련의 계획 수립

2) 분석 기획의 특징

- 분석 대상과 방법에 따른 분류 : 분석 주체와 방법에 대한 특성상 4가지 유형을 넘나들며 분석을 하고 결과를 도출하는 과정 반복
- 목표 시점에 따른 분류
    - 단기적 접근 방식 (과제 중심적 접근)
        - 당연한 과제를 빠르게 해결하기 위한 목적
        - 명확한 해결을 위해 Quick-Win 방식으로 분석
    - 중장기적 접근 방식 (마스터 플랜 접근)
        - 지속적인 분석 문화를 내재화하기 위한 목적
        - 전사적으로 장기적 관점에서 과제를 도출하여 수행
    - 혼합 방식 (분석 기획 시 적합)
        - 마스터 플랜을 수립하고 장기적 관점에서 접근하는 것이 바람직
        - 분석의 가치를 증명하고 이해관계자들의 동의를 얻기 위해 과제를 빠르게 해결하여 그 가치를 조기에 체험

3) 분석 기획 시 필요역령

- 분석 기획을 위한 기본적인 소망 : 분석 기획은 도메인 지식과 정보기술, 수학 및 통계학적 지식이라는 3가지 역량에 대한 균형 잡힌 시각을 갖고서 분석의 방향성과 계획을 수립하는 것
- 프로젝트 관리 역량과 리더십 : 분석 기획 시 기본적인 3가지 소양과 함께 프로젝트 관리 역량과 분석 프로젝트를 잘 이끌어 갈 리더십 중요

4) 분석 기획 시 고려사항

- 사용 가능한 데이터 확인
    - 데이터 확보 가능 여부, 데이터의 유형 등은 미리 확인
    - 데이터의 유형에 따라 적용 가능한 솔루션이나 분석 방법론이 달라짐
- 적합한 사례 탐색
    - 기존에 잘 구현되어 활용되고 있는 유사 분석 시나리오나 솔루션이 있다면 이를 최대한 활용하는 것이 유리
    - 분석 결과를 활용할 사용자의 측면에서 공감대를 얻을 수 있으며, 분석 수행이 원활하게 될 수 있도록 도와줌
- 분석 수행 시 발생 가능한 요소 고려
    - 분석 결과의 정확도를 높이기 위하여 기간과 투입 자원 증가가 불가피하며, 이로 인한 비용 상승을 충분히 고려
    - 분석 결과를 실제 환경에서도 성능에 문제없이 적용할 수 있도록 충분히 고려

### 03. 분석 마스터 플랜과 로드맵 설정

1) 분석 마스터 플랜 : 분석 관제를 수행함에 있어 그 과제의 목적이나 목표에 따라 전체적인 방향성을 제시하는 기본계획

- 분석 마스터 플랜 수립 절차
    - 분석 마스터 플랜 시 일반적인 정보전략계획 방법론을 활용할 수 있다. 다만 데이터 분석 기획의 특성을 고려하여 수행
    - 과제 도출 방법을 활용하여 데이터 분석 과제들을 빠짐없이 정의
    - 분석 과제의 중요도와 난이도 등을 고려하여 우선순위 결정
    - 단기와 중장기로 나누어 분석 로드맵을 수립
- 정보전략계획(ISP)
    - 정보기술 및 시스템을 전략적으로 활용하기 위한 중장기 마스터 플랜을 수립하는 절차
    - 조직 내·외부의 환경을 충분히 분석하여 새로운 기회나 문제점 도출
    - 사용자의 요구사항을 확인하여 시스템 구축 우선순위를 결정

2) 분석 과제 우선순위 평가기준

- IT 프로젝트의 과제 우선순위 평가기준 : 전략적 중요도, 실행 용이성 등 기업에서 고려하는 중요 가치 기준에 따라 다양한 관점으로 과제 우선수누이 기준을 정의하여 평가

|평가관점|평가요소|내용|
|---|---|---|
|전략적 중요도|전략적 필요성|비즈니스 목표나 업무에 얼마나 밀접하게 연관되어 있는지 측정|
|전략적 중요도|시급성|사용자 요구사항 반영이나 업무능률을 향상시키기 위해 얼마나 시급하게 수행되어야 하는지 측정|
|실행 용이성|투자 용이성|과제를 수행하는 데 필요한 비용이나 투자예산의 확보 가능성 정도를 측정|
|실행 용이성|기술 용이성|과제에 적용할 기술의 안정성 검증 정도와 유지보수가 용이한지 측정|

- 데이터 분석 프로젝트의 우선순위 평가기준 : 기존 IT 프로젝트와는 다른 기준으로 우선순위 평가 기준을 정의하여야 하며, 과제를 수행하고자 하는 기업이 처한 상황에 따라 그 기준이 달라질 수 있음

|ROI 요소|특징|내용|
|---|---|---|
|투자비용 요소|데이터 크기|데이터 규모, 데이터 양|
|투자비용 요소|데이터 형태|데이터 종류, 데이터 유형|
|투자비용 요소|데이터 속도|데이터 생산속도, 데이터 처리속도|
|비즈니스 효과|새로운 가치|분석 결과 활용을 통한 획득 가치, 비즈니스 실행을 통한 획득 가치|

- 분석 ROI 요소를 고려한 과제 우선순위 평가기준 : 조직의 상황에 따라 난이도 조율
     - 분석 준비도와 성숙도 진단 결과를 활용해 조직의 분석 수준 파악
     - 파악된 수준을 기초로 하여 적용 범위와 수행 방법별 난이도 조정

|평가관점|평가요소|내용|ROI 요소|
|---|---|---|---|
|시급성(중요)|전략적 중요도|목표가치|현재의 관점에 전략적 가치를 둘 것인지 판단, 중장기적 관점에 전략적인 가치를 둘 것인지 판단|비즈니스 효과|
|난이도|데이터 획득 비용, 데이터 가공 비용, 데이터 저장 비용, 분석 적용 비용, 분석 수준|비용과 범위 측면에서 적용하기 쉬운 과제인지 판단, 과제 범위를 PoC 또는 처음부터 크게 할 것인지 판단, 내부 데이터를 활용하고 외부 데이터까지 확대할지 판단|투자비용 요소|

3) 분석 과제 우선순위 선정 및 조정

- 포트폴리오 사분면 분석 기법 활용 : 난이도와 식브성을 기준으로 분석 과제 유형을 분류하여 4분면에 배치
- 매트릭스 내 분석 과제 우선순위 선정
    - 가장 우선적으로 분석 과제 적용이 필요한 영역은 3사분면
    - 우선순위가 낮은 영역은 2사분면
    - 적용 우선순위 기준을 시급성에 둘 경우 : 3->4->1->2 영역
    - 적용 우선순위 기준을 난이도에 둘 경우 : 3->1->4->2 영역
- 매트릭스 내 분석 과제 우선순위 조정
    - 시급성이 높고 난이도가 높은 1사분면은 의사결정을 통해 적용 우선순위 조정 가능
    - 데이터 양과 특성, 분석 범위 등에 따라 난이도를 조율하여 적용 우선순위를 조정 가능
- 분석 과제 우선순위 조정 시 고려사항
    - 기술적 요소에 따른 적용 우선순위 조정
        - 대용량 데이터 분석은 데이터 저장, 처리, 분석을 위한 새로운 기술 요소들로 인하여 운영중인 시스템에 영향을 줄 수 있음
        - 기존 시스템에 미치는 영향을 최소화하여 적용하거나 운영중인 시스템과 별도로 시행하여 난이도 조율을 통한 우선순위 조정 가능
    - 분석 범위에 따른 우선순위 조정
        - 분석 과제의 전체 범위를 한 번에 일괄적으로 적용하여 추진 가능
        - 분석 과제 중 일부만 PoC로 진행하고 평가 후에 범위를 확대 가능

4) 분석 로드맵 설정 : 분석 로드맵은 마스터 플랜에서 정의한 목표를 기반으로 분석 과제를 수행하기 위해 필요한 기준 등을 담아 만든 종합적인 계획

- 분석 로드맵 수립 절차
    - 최종적인 실행 우선순위를 결정하여 단계적 구현 로드맵 수립
    - 단계별로 추진하고자 하는 목표를 명확하게 저으이
    - 추진 과제별 선행 관계를 고려하여 단계별 추진 내용 정렬
- 세부적인 일정계획 수립
    - 반복적인 정련과정을 통해 프로젝트의 완성도를 높여 나감
    - 데이터 수집 및 확보와 분석 데이터 준비 단계는 순차적으로 진행하고 모델링 단계는 반복적으로 수행
    - 주로 순차형과 반복형을 혼합하여 사용

### 04. 분석 문제 정의

1) 분석 문제 정의 개요

- 분석 과제 도출 : 분석 과제는 해결해야 할 다양한 문제들을 데이터 분석 문제로 변환하여 분석 프로젝트로 수행할 수 있는 과제정의서 형태로 도출
- 대표적인 분석 과제 도출 방법 : 문제가 먼저 주어지고 이에 대한 해법을 찾아가는 하향식 접근 방식과 데이터를 기반으로 문제의 재정의 및 해결방안을 탐색하는 상향식 접근 방식
- 최적인 의사결정을 위한 혼합방식
    - 동적인 환경에서 발산과 수렴 단계를 반복적으로 수행하며 상호 보완을 통해 분석의 가치를 극대화
    - 상향식 접근 방식의 발산 단계 : 가능한 옵션을 도출
    - 하향식 접근 방식의 수렴 단계 : 도출된 옵션을 분석하고 검증
- 분석 과제 정의
    - 분석 과제 정의서는 다양한 방식으로 도출한 분석 과제들을 명확하게 정의하여 상세하게 작성
        - 필요한 데이터, 데이터 수집과 분석 난이도, 분석 방법과 수행 주기, 상세 분석 과정, 분석 결과에 대한 검증 책임자 등을 포함
        - 분석 데이터는 조직 내부뿐만 아니라 외부 데이터도 포함, 데이터 유형이나 종류를 가리지 않고 범위를 확장하여 고려
    - 분석 과제 정의서는 분석 프로젝트를 수행하는 이해관계자가 프로젝트의 방향을 설정하고 성공 여부를 판단할 수 있는 자료로 사용 : 분석 과제 정의서는 향후 프로젝트 수행계획의 입력물로 사용

2) 하향식 접근 방식 : 문제가 주어지고 이에 대한 해법을 찾기 위하여 각 과정이 체계적으로 단계화되어 수행하는 방식

- 문제 탐색 단계
    - 개별적으로 인지하고 있는 문제를 단순하게 나열하는 것보다 전체적인 관점의 기준 모델을 활용하여 누락 없이 문제를 도출하고 식별
    - 현재 데이터의 소유 여부와 데이터가 없는 경우 해결방안 등에 대한 세부적인 내용보다 문제를 해결하여 발생하는 가치에 중심을 두어야 함
        - 비즈니스 모델 기반 문제 탐색
            - 해당 기업이 사업 모델을 도식화한 비즈니스 모델 캔버스의 블록을 단순화하여 기회를 추가로 도출
            - 새로운 관점의 접근으로 새로운 유형의 분석 기회와 주체를 발굴
        - 외부 참조 모델 기반 문제 탐색
            - 유사 또는 동종의 환경에서 기존에 수행한 분석 사례와 벤치마킹
            - 제공되는 산업별, 업무 서비스별 분석테마 후보 그룹을 통해 빠르고 쉬운 방식으로 접근
        - 분석 유즈케이스 정의
            - 도출한 분석 기회들을 구체적인 과제로 만들기 전에 분석 유즈케이스로 정의하여야 함
            - 문제에 대한 상세 설명과 기대효과를 명시하여 향후 데이터 분석 문제로의 전환 및 적합성 평가에 활용
- 문제 정의 단계
    - 식별된 비즈니스 문제를 데이터적인 문제로 변환하여 정의
    - 필요한 데이터와 기법을 정의하기 위한 데이터 분석 문제로 변환
    - 분석 수행자 외 문제 해결 시 효율을 얻을 최종 사용자 관점에서 정의
- 해결방안 탐색 단계
    - 정의된 데이터 분석 문제를 해결하기 위한 다양한 방안들 모색
    - 기법 및 시스템과 분석 역량 보유 여부에 따라 세분화 가능
- 타당성 평가 단계 : 도출된 분석 문제, 가설에 대한 대안을 과제화하기 위한 타당성 분석
    - 경제적 타당성
        - 비용 대비 편익 분석 관점의 접근 필요
        - 항목은 데이터, 시스템, 인력, 유지보수 등 분석 비용
        - 편익은 분석 결과를 적용하여 발생 가능한 실질적 비용 절감, 추가적 매출과 수익 등의 경제적 가치로 산출
    - 데이터 및 기술적 타당성
        - 데이터 분석 시 데이터, 분석 시스템 환경 분석역량 필요
        - 기술적 타당성 분석 시 역량 확보 방안의 사전수립 필요
        - 비즈니스 분석가, 데이터 분석가, 시스템 엔지니어 등과 협업

3) 하향식 접근 방식의 문제 탐색 방법

- 비즈니스 모델 캔버스를 활용한 과제 발굴 : 해당 기업의 사업 모델을 도식화한 비즈니스 모델 캔버스의 9가지 블록을 단순화하여 문제 발굴을 3개의 단위로, 이를 관리하는 2개의 영역으로 도출
    - 업무 단위 : 제품이나 서비스를 생산하기 위한 내부 프로세스 및 주요 자원과 관련하여 주제 도출
    - 제품 단위 : 생산 및 제공하는 제품이나 서비스를 개선하기 위한 관련 주제들 도출
    - 고객 단위 : 제품이나 서비스를 제공받는 사용자나 고객 도는 이를 제공하는 채널 관점에서 관련 주제들 도출
    - 규제와 감사 영역 : 제품 생산과 전달 과정에서 발생하는 규제나 보안 관점에서 관련 주제들 도출
    - 지원 인프라 영역 : 분석을 수행하는 시스템 영역과 이를 운영 및 관리하는 인력의 관점에서 관련 주제들 도출
- 분석 기회 발굴의 범위 확장 : 새로운 문제의 발굴이나 장기적인 접근을 위해서는 환경과 경쟁 구도의 변화 및 역량의 재해석을 통한 혁신 관점의 분석 기회 추가 도출 필요

|관점|영역|내용|
|---|---|---|
|거시적 관점|사회 영역|고객영역을 확장하여 전체 시장을 사회, 문화, 구조적 트렌드 변화에 기반하여 분석 기회 도출|
|거시적 관점|기술 영역|과학, 기술, 의학 등 최신 기술의 등장변화에 따른 역량 내재화와 제품 및 서비스 개발에 대한 분석 기회 도출|
|거시적 관점|경제 영역|산업과 금융 전반의 변동성과 경제 구조 변화 동향에 따른 시장 흐름을 파악하고 이에 대한 분석 기회 도출|
|거시적 관점|환겨 영역|환경과 관련된 정부, 사회단체, 시민사회의 관심과 규제 동향을 파악하고 이에 대한 분석 기회 도출|
|거시적 관점|정치 영역|주요 정책방향, 정세, 지정학적 동향 등의 거시적인 흐름을 토대로 하여 분석 기회 도출|
|경쟁자 확대 관점|대체재 영역|현재 생산하고 있는 제품 또는 서비스의 대체재를 파악하고 이를 고려한 분석 기회 도출|
|경쟁자 확대 관점|경쟁자 영역|현재 생산하고 있는 제품이나 서비스의 주요 경쟁자에 대한 동향을 파악하여 이를 고려한 분석 기회 도출|
|경쟁자 확대 관점|신규 진입자 영역|향후 시장에서 파괴적인 역할을 수행할 수 있는 신규 진입자에 대한 동향을 파악하여 이를 고려한 분석 기회 도출|
|시장의 니즈 탐색 관점|고객 영역|고객의 구매 동향 및 고객의 컨텍스트를 더욱 깊게 이해하여 제품 또는 서비스의 개선에 필요한 분석 기회 도출|
|시장의 니즈 탐색 관점|채널 영역|자체 채널뿐만 아니라 최종 고객에게 상품이나 서비스를 전달 가능한 모든 경로를 파악하여 경로별 채널 분석 기회를 확대하여 탐색|
|시장의 니즈 탐색 관점|영향자들 영역|주주, 투자자, 협의 및 기타 이해관계자의 주요 관심사항에 대하여 파악하고 분석 기회 탐색|
|역량의 재해석 관점|내부 역량 영역|지식, 기술, 스킬 등 노하우와 인프라적인 유형 자산에 대해서도 폭넓게 재해석하고 해당 영역에서 분석 기회 탐색|
|역량의 재해석 관점|파트너와 네트워크 영역|관계사와 공급사 등의 역량을 활용해 수행할 수 있는 기능을 파악해 보고 이에 대한 분석 기회를 추가적으로 도출|

4) 상향식 접근 방식 : 문제의 정의 자체가 어려운 경우 데이터를 기반으로 문제의 재정의 및 해결방안을 탐색하고 이를 지속적으록 개선하는 방식

- 상향식 접근 방식의 특징
    - 다양한 데이터 분석을 통해 왜 그러한 일이 발생하는지 역으로 추적하면서 문제를 도출하거나 재정의할 수 있는 방식
    - 데이터를 활용하여 생각지도 못했던 인사이트 도출 미 시행착오를 통한 개선 가능
- 상향식 접근 방식의 등장 배경
    - 기존 하향식 접근 방식의 한계를 극복하기 위해 등장
        - 하향식 접근 방식은 솔루션 도출은 유효하지만 새로운 문제 탐색을 어려움
        - 하향식 접근 방식은 복잡하고 다양한 환경에서 발생한 문제에는 부적합
    - 논리적 단계별 접근법은 문제의 구조가 분명하고 이에 대한 해결책을 도출하기 위한 데이터가 분석가나 의사결정자에게 주어져 있음을 가정하고 있음
- 상향식 접근기반 전통적 분석 사고 극복방안
    - 디자인 사고 접근법
        - 현장 관찰과 감정이입, 대상 관점으로의 전환 수행
        - 통상적으로는 분석적으로 사물을 인식하려는 Why를 강조하거나, 답을 미리 내는 것이 아니라 사물을 있는 그대로 인식하려는 What 관점으로 접근
        - 객관적으로 존재하는 데이터 자체를 관찰하고 실제 행동을 옮김으로써 대상을 좀 더 잘 이해하는 방식으로 접근
    - 비지도학습 방법에 의한 수행
        - 목표값을 사전에 학습하거나 정의하지 않고 데이터 자체만을 가지고 결과물 도출
        - 새로운 유형의 인사이트를 도출하기에 유용한 방식
    - 빅데이터 환경에서의 분석
        - 통계적 분석환경에서는 인과관계 분석을 위해 가설을 설정하고 이를 검증하기 위해 모집으로부터 표본을 추출하여 가설검증
        - 빅데이터 분석환경에서는 인과관계, 상관관계, 연관분석을 통하여 다양한 문제 해결 가능
- 상향식 접근 방식의 문제 해결 방법
    - 프로토타이핑 접근법 : 일단 먼저 분석을 시도해 보고 그 결과를 확인하면서 반복적으로 개선해 나가는 방식
        - 사용자가 요구사항이나 데이터를 정확히 정의하기 어렵고 원천 데이터라도 명확하지 않을 때 주로 사용
        - 완전하지는 않지만 신속하게 해결책이나 모형을 제시하여 이를 바탕으로 문제를 더 명확하게 인식하고 필요한 데이터를 식별하여 구체화

### 05. 데이터 분석 방안

1) 분석 방법론

- 분석 방법론
    - 데이터 분석 시 품질확보를 위하여 단계별로 수행해야 하는 활동, 작업, 산출물 정의
    - 프로젝트는 한 개인의 역량이나 조직의 우연한 성공에 의해서는 안 되고 일정 품질 수준 이상의 산출물과 프로젝트의 성공 가능성 제시해야 함
- 분석 방법론의 구성요건
    - 상세한 절차
    - 방법
    - 도구와 기법
    - 템플릿과 산출물
    - 어느 정도의 지식만 있으면 활용 가능한 수준의 난이도
- 분석 방법론의 생산과정(선순환 과정)
    - 형식화
        - 개인의 암묵지가 조직의 형식지로 발전
        - 분석가의 경험을 바탕으로 정리하여 문서화
    - 체계화
        - 문서화한 최적화된 형식지로 전개됨으로써 방법론 생성됨
        - 문서에는 절차나 활동 및 작업, 산출물, 도구 등을 정의
    - 내재화
        - 개인에게 전파되고 활용되어 암묵지로 발전됨
        - 전파된 방법론을 학습하고 활용하여 내재화

2) 계층적 프로세스 모델 구성 : 분석 방법론은 일반적으로 계층적 프로세스 모델 형태로 구성 가능하며, 단계, 태스크, 스텝 3계층으로 구성됨

- 최상위 계층(단계)
    - 프로세스 그룹을 통하여 완성된 단계별 산출물 생성
    - 각 단계는 기준선으로 설정되어 관리되어야 하며 버전관리 등을 통하여 통제
- 중간 계층 (태스크)
    - 각 태스크는 단계를 구성하는 단위 활동
    - 물리적 또는 논리적 단위로 품질검토 가능
- 최하위 계층 (스텝)
    - WBS의 워크패키지
    - 입력자료, 처리 및 도구, 출력자료로 구성된 단위 프로세스

3) 소프트웨어개발생명주기 활용

- 분석 방법론은 소프트웨어 공학의 소프트웨어개발생명주기를 활용하여 구성 : 소프트웨어개발생명주기는 소프트웨어에 대해 요구분석과 설계, 구현과정을 거쳐 설치, 운영과 유지보수, 그리고 폐기할 때까지의 전 과 정을 가시적으로 표현
    - 계획(요구명세)
        - 고객의 요구사항 명세
        - 타당성 조사 및 소프트웨어의 기능과 제약조건 정의하는 명세서 작성
        - 요구사항은 일반적으로 모호하고 불완전하며 모순
    - 요구분석 : 대상이 되는 문제 영역과 사용자가 원하는 Task 이해
    - 설계 : 분석모형을 가지고 이를 세분화함으로써 구현될 수 있는 형태로 전환
    - 구현 : 실행 가능한 코드 생성
    - 시험 : 발생 가능한 실행 프로그램의 오류 발견, 수정
    - 유지보수 : 인수가 완료된 후 일어나는 모든 개발 활동
- 폭포수 모형 : 고전적 Life Cycle Paradigm으로 분석, 설계, 개발, 구현, 시험 및 유지보수 과정을 순차적으로 접근하는 방법
    - 소프트웨어 개발을 단계적, 순차적, 체계적 접근 방식으로 수행
    - 개념 정립에서 구현가지 하향식 접근 방법 사용
    - 전 단계의 산출물은 다음 단계의 기초
- 프로토타입 모형 : 사용자의 요구사항을 충분히 분석할 목적으로 시스템의 일부분을 일시적으로 간략히 구현한 다음 다시 요구사항을 반영하는 과정을 반복하는 개발모형
    - 실험적 프로토타입 : 요구분석의 어려움을 해결하기 위해 실제 개발될 소프트웨어의 일부분을 직접 개발함으로써 의사소통의 도구로 활용
    - 진화적 프로토타입 : 프로토타입을 요구분석의 도구로만 활용하는 것이 아니라, 이미 개발된 프로토타입을 지속적으로 발전시켜 최종 소프트웨어로 발전
    - 요구 분석의 어려움 해결을 통해 사용자의 참여 유도
    - 요구사항 도출과 이해에 있어 사용자와의 커뮤니케이션 수단으로 활용 가능
    - 사용자 자신이 원하는 것이 무엇인지 구체적으로 잘 모르는 경우 간단한 시제품으로 개발 가능
    - 개발 타당성을 검토하는 수단으로 활용 가능
- 나선형 모형 : 시스템을 개발하면서 생기는 위험을 최소화하기 위해 나선을 돌면서 점진적으로 완벽한 시스템으로 개발하는 모형
    - 프로젝트의 완전성 및 위험 감소와 유지보수 용이
    - 관리가 중요하나 매우 어렵고 개발시간이 장기화될 가능성이 있음
- 반복적 모형 : 사용자의 요구사항 일부분 혹은 제품의 일부분을 반복적으로 개발하여 최종 시스템으로 완성하는 모형
    - 증분형 모형 : 사용자 요구사항 제품의 일부분을 반복적으로 개발하며 대상범위를 확대해 나아가서 최종제품을 완성하는 방법
    - 진화형 모형 : 시스템이 가지는 여러 구성요소의 핵심부분을 개발한 후 각 구성요소를 지속적으로 발전시켜 나가는 방법

|유형|설명|장점|단점|
|---|---|---|---|
|폭포수 모형|검토 및 승인을 거쳐 순차적, 하향식으로 개발 진행|이해하기 쉽고 관리 용이, 다음 단계 진행 전에 결과 검증|요구사항 도출 어려움, 설계 및 코딩과 테스트 지연, 문제점 발견이 늦어짐|
|프로토타입 모형|시스템의 핵심적인 기능을 먼저 만들어 평가한 후 구현|요구사항 도출과 시스템 이해 용이, 의사소통 향상|사용자의 오해(완제품)가 발생 쉬움, 폐기되는 프로토타입 존재|
|나선형 모형|폭포수 모형과 프로토타입의 모형의 장점에 위험분석 추가|점증적으로 개발 시 실패 위험을 감소시킬 수 있음, 테스트가 용이하고 피드백이 있음|관리가 복잡|
|반복적 모형|시스템을 여러 번 나누어 릴리즈|

- 소프트웨어게빌생명주기 모형 선정 기준
    - 프로젝트의 규모와 성격
    - 개발에 사용되는 방법과 도구
    - 개발에 소요되는 시간과 비용
    - 개발과정에서의 통제수단과 소프트웨어 산출물 인도 방식

4) KDD 분석 방법론 : 통계적인 패턴이나 지식을 탐색하는 데 활용할 수 있도록 체계적으로 정리한 프로파일링 기술 기반의 데이터 마이닝 프로세스

- KDD 분석 방법론의 9가지 프로세스
    - 1. 분석 대상 비즈니스 도메인의 이해
    - 2. 분석 대상 데이터셋 선택과 생성
    - 3. 데이터에 포함되어 있는 잠음과 이상값 등을 제거하는 정제작업이나 선처리
    - 4. 분석 목적에 맞는 변수를 찾고 필요시 데이터의 차원을 축소하는 데이터 변경
    - 5. 분석 목적에 맞는 데이터 마이닝 기법 선택
    - 6. 분석 목적에 맞는 데이터 마이닝 알고리즘 선택
    - 7. 데이터 마이닝 시행
    - 8. 데이터 마이닝 결과에 대한 해석
    - 9. 데이터 마이닝에서 발견된 지식 활용

- KDD 분석 방법론의 분석 절차 : 데이터 분석은 데이터셋 선택, 데이터 전처리, 데이터 변환, 데이터 마이닝, 데이터 마이닝 결과 평가 총 5단계에 걸쳐 진행
    - 데이터셋 선택
        - 분석대상 비즈니스 도메인에 대한 이해 및 프로젝트 목표의 정확한 설정 선행
        - 데이터베이스 또는 원시 데이터에서 분석에 필요한 데이터를 선택
        - 필요시에 목표 데이터를 추가적으로 구성하여 활용
    - 데이터 전처리
        - 잡음과 이상값, 결측치를 식별하고 필요시 제거하거나 대체
        - 데이터가 추가적으로 필요한 경우 데이터셋 선택 절차부터 다시 실행
    - 데이터 변환
        - 분석 목적에 맞는 변수를 선택하거나 데이터의 차원 축소 등 수행
        - 학습용 데이터와 검증용 데이터로 데이터 분리
    - 데이터 마이닝
        - 분석 목적에 맞는 데이터 마이닝 기법 및 알고리즘 선택하여 분석 수행
        - 필요시 데이터 전처리와 데이터 변환 절차를 추가로 실행하여 데이터 분석 결과의 품질을 높일 수 있음
    - 데이터 마이닝 결과 평가
        - 분석 결과에 대한 해석과 평가 및 분석 목적과의 일치성 확인
        - 발견된 지식을 업무에 활용하기 위한 방안 모색
        - 필요한 경우 데이터셋 선택부터 데이터 마이닝 절차가지 반복하여 수행

5) CRISP-DM 분석 방법론 : 계층적 프로세스 모델로써 4계층으로 구성된 데이터 마이닝 프로세스

- CRISP-DM 분석 방법론의 4계층
    - 최상위 레벨 : 여러 개의 단계로 구성
    - 일반화 태스크 : 데이터 마이닝의 단일 프로세스를 완전하게 수행하는 단위
    - 세분화 태스크 : 일반화 태스크를 구체적으로 수행
    - 프로세스 실행 : 데이터 마이닝을 구체적으로 실행

6) SEMMA 분석 방법론 : SAS Institute의 주도로 만들어진 기술과 통계 중심의 데이터 마이닝 프로세스

- SEMMA 분석 방법론의 특징
    - SAS Institute의 데이터 마이닝 도구와 손쉽게 접목하여 활용 가능
    - 주로 데이터 마이닝 프로젝트의 모델링 작업에 중점

### 06. 빅데이터 분석 방법론

1) 빅데이터 분석 방법론 개요

- 분석 방법론은 응용 서비스 개발을 위한 3계층으로 구성
    - 단계
        - 데이터 분석을 수행하기 위한 절차
        - 기준선을 설정하고 버전관리를 통해 통제되어야 함
    - 태스크
        - 각 단계별로 수행되어야 하는 세부 업무
        - 각 태스크가 완료되면 그에 대한 성과를 얻을 수 있음
    - 스텝
        - 단기간 내에 수행 가능한 워크패키지
        - 입력자료, 처리 및 도구, 출력자료로 구성된 단위 프로세스

2) 빅데이터 분석 방법론의 개발절차

- 분석 기획
    - 비즈니스 이해 및 범위 설정
        - 향후 프로젝트 진행을 위한 방향을 설정, 프로젝트 목적에 부합한 범위를 설정
        - 프로젝트의 범위를 명확하게 파악하기 위해 구조화된 명세서 작성
    - 프로젝트 정의 및 계획 수립
        - 모형의 운영 이미지를 설계하고 모형 평가 기준 설정
        - 프로젝트의 목표 및 KPI, 목표 수준 등을 구체화하여 상세 프로젝트를 정의하고 수행 계획을 세움
        - 프로젝트 산출물을 중심으로 WBS를 작성
    - 프로젝트 위험계획 수립
        - 프로젝트를 진행하면서 발생 가능한 모든 위험을 식별하여 사전 대응방안 수립
        - 예상되는 위험에 대한 대응은 회피, 전이, 완화, 수용으로 구분하여 우험 관리 계획서 작성
- 데이터 준비
    - 필요 데이터 정의
        - 정형, 비정형, 반정형 등 모든 내외부 데이터를 대상으로 데이터의 속성, 오너, 관련 시스템 담당자 등을 포함한 데이터 정의서 작성
        - 내부 데이터 획득 시 부서 간 업무협조와 개인정보보호 및 정보보안과 관련된 문제점을 사전에 파악
        - 외부 데이터 획득 시 시스템 간 다양한 인터페이스 및 법적 이슈를 고려
    - 데이터 스토어 설계
        - 정형, 비정형, 반정형 데이터를 모두 저장할 수 있도록 설계
        - 데이터의 효율적인 저장과 활용을 위해 데이터 스토어의 논리적, 물리적 설계를 구분하여 수행
    - 데이터 수집 및 정합성 점검
        - 크롤링, 시스템 간 실시간 처리, 배치 처리, 데이터베이스 간 연동, API를 이용한 개발, ETL 도구 활용, 스크립트 작성 등 다양한 방법
        - 데이터 거버넌스에 근거하여 메타 데이터 및 데이터 사전 등이 작성되어 적용되고 있는지 주기적으로 확인
        - 데이터 품질개선이 필요한 부분에 대하여 보완 작업 진행
- 데이터 분석
    - 분석용 데이터 준비
        - 분석에 필요한 데이터의 범위를 확인하여 데이터베이스나 구조화된 형태 구성
        - 필요한 경우 적절한 가공을 통하여 입력 데이터로 사용될 수 있도록 함, 분석용 작업 공간과 전사 차원의 데이터 스토어로 분리 가능
    - 텍스트 분석
        - 데이터 스토어에서 필요한 텍스트 데이터를 추출하여 다양한 기법으로 분석하고 모형 구축
        - 텍스트 분석 결과는 모델링 태스크와 연동하여 프로젝트 목적에 부합하는 최종 모형 구축
        - 구축된 모형은 텍스트 시각화 도구로 모형의 의미 전달을 명확화함
    - 탐색적 분석
        - 분석용 데이터셋에 대한 정합성 검토, 데이터 요약, 데이터 특성을 파악하고 모델링에 필요한 데이터 편성
        - 다양한 관점으로 평균, 분산 등 기초 통계량을 산출하여 데이터의 분포와 변수간의 관계 등 데이터 자체의 특성과 통계적 특성 파악
        - 시각화를 탐색적 데이터 분석을 위한 도구로 활용하여 데이터의 가독성을 명확히 하고 데이터의 형상 및 분포 등 데이터 특성 파악
    - 모델링
        - 기계학습 등을 이용한 데이터 모델링은 훈련용 데이터를 활용하여 분류, 예측, 군집 등의 모형을 만들어 가동 중인 운영 시스템에 적용
        - 필요한 경우 비정형 데이터 분석결과를 통합적으로 활용하여 포르젝트 목적에 맞는 통합 모델링 수행
        - 개발된 모형을 활용하기 위해 상세한 알고리즘 설명시 작성과 모니터링 방안 필요
    - 모델 평가 및 검증
        - 프로젝트 정의서의 평가 기준에 따라 모형의 완성도 평가
        - 품질관리 차원에서 모형 평가 프로세스 진행
        - 모형 결과 보고서 내의 알고리즘을 파악하고 테스트용 데이터나 검증을 위한 별도의 데이터를 활용하여 모형의 객관성과 실무 적용성 검증
        - 요구되는 성능 목표에 미달하는 경우 모형 튜닝 작업 수행
- 시스템 구현
    - 설계 및 구현
        - 시스템 및 데이터 아키텍처와 사용자 인터페이스 설계 진행
        - 시스템 설계서를 바탕으로 BI 패키지를 활용하거나 프로그래밍을 통하여 모형 구현
    - 시스템 테스트 및 운영
        - 시스템 테스트는 품지로간리 차원에서 진행함으로써 적용된 시스템의 객관성과 완전성 확보
        - 시스템 운영자, 사용자를 대상으로 필요한 교육 실시
- 평가 및 전개
    - 모델 발전계획 수립
        - 모형의 생명주기를 설정하고 주기적인 평가를 실시하여 모형을 유지보수하거나 재구축하기 위한 방안 마련
        - 발전계획을 상세하게 수립하여 모형의 계속성을 확보
    - 프로젝트 평가 및 보고
        - 프로젝트 성과를 정량적 성과, 정성적 성과로 나눠 성과 평가서 작성
        - 프로젝트 진행과정에서 산출된 지식이나 프로세스 등 산출물 자산화

### 07. 데이터 분석 거버넌스

1) 데이터 분석 거버넌스 개요

- 데이터 분석 거버넌스의 필요성 : 데이터 분석 업무를 하나의 기업 문화로 정착하고 이를 지속적으로 고도화 해 나가기 위함
- 데이터 분석 거버넌스의 구성요소
    - 데이터 분석 기획과 관리를 수행하는 조직
    - 데이터 분석 과제 기획과 운영 프로세스
    - 데이터 분석 지원 인프라
    - 데이터 거버넌스
    - 데이터 분석 교육 및 마인드 육성 체계

3) 데이터 분석 과제 기획과 운영 프로세스

- 데이터 분석 과제 관리 프로세스의 구성
    - 과제 발굴 단계
        - 개별 조직이나 개인이 도출한 데이터 분석 아이디어 발굴
        - 발굴된 아이디어를 과제화하여 데이터 분석 과제 풀로 관리
        - 데이터 분석 프로젝트를 선정하는 작업 수행
    - 과제 수행 및 모니터링 단계
        - 데이터 분석을 수행한 팀 구성
        - 데이터 분석 과제 실행 시 지속적인 모니터링 수행
        - 데이터 분석 과제 결과를 공유하고 개선
- 데이터 분석 과제 관리 프로세스의 특징
    - 조직 내에 데이터 분석 문화를 내재화하여 경쟁력 확보
    - 결과물을 잘 축적하여 관리함으로써 향후 유사 데이터 분석 과제 수행 시 시행착오 최소화
    - 데이터 분석 프로젝트를 효율적으로 진행 가능

4) 데이터 분석 지원 인프라

- 데이터 분석 플랫폼 구축
    - 데이터 분석 마스터 플랜을 기획하는 단계에서부터 장기적, 지속적, 안정적으로 활용할 수 있도록 고려
        - 단기적으로 구축하기 쉬운 개별 시스템보다는 확장성을 고려한 플랫폼 구조 도입 적절
        - 개별 시스템
            - 시스템 간 자체적인 데이터 교환
            - 시스템별 독립적인 데이터 관리
            - 확장 시 시스템 간 인터페이스 폭증
        - 플랫폼 구조
            - 분석 플랫폼을 활용한 공동기능 활용
            - 중앙집중적 데이터 관리
            - 시스템 간 인터페이스 최소화
- 데이터 분석 플랫폼 : 데이터 분석 서비스를 위한 응용프로그램이 실행될 수 있는 환경과 기초를 이루는 컴퓨터 시스템
- 데이터 분석 플랫폼의 특징
    - 데이터 분석에 필요한 프로그래밍 및 실행, 이를 서비스할 수 있는 환경을 제공
    - 새로운 데이터 분석 니즈가 발생할 경우 개별 시스템을 추가힞 않으면서도 추가적인 서비스 제공 가능 (확장성 증대)

5) 데이터 거버넌스

- 데이터 거버넌스의 필요성
    - 개별 시스템 단위로 데이터를 관리할 경우 데이터 중복, 비표준화에 따른 정합성 오류 등으로 데이터 활용도 저하
    - 빅데이터 프로젝트의 효과적 추진 및 효과의 지속성을 얻기 위해서는 데이터 거버넌스 체계 수립 필요 : 데이터 거버넌스가 없는 빅데이터의 적용은 단발성 효과에 불과할 가능성이 높음
- 데이터 거버넌스 : 전사 차원의 모든 데이터에 대하여 정책 및 지침, 표준화, 운영조직과 책임 등의 표준화된 관리 체계를 수립하고 운영하기 위한 프레임워크와 저장소를 구축
- 데이터 거버넌스의 주요 관리 대상
    - 마스터 데이터 : 마스터 파일을 형성하는 데이터이며, 데이터를 처리 및 조작하기 위하여 사용되는 기본 데이터
    - 메타 데이터 : 데이터에 대한 구조화된 데이터이며, 다른 데이터를 설명하기 위해 사용되는 데이터
    - 데이터 사전 : 효과적인 데이터 자원관리를 위해 자료의 이름, 표현 방식, 자료의 의미와 사용 방식, 다른 자료와의 관계 등을 저장해놓은 데이터
- 데이터 거버넌스의 특징
    - 데이터의 가용성, 유용성, 통합성, 보안성, 안전성을 확보 가능
    - 빅데이터 프로젝트를 성공으로 이끄는 기반을 마련
    - 독자적인 구축도 가능하지만 전사 차원의 IT거버넌스나 EA의 구성요소가 될 수 있음
- 빅데이터 거버넌스의 특징
    - 데이터 거버넌스에 추가적으로 빅데이터가 갖는 고유한 특성들을 고려하여 관리 체계 수립 : 빅데이터의 효율적 관리, 다양한 데이터의 관리체계, 데이터 최적화, 정보보호, 데이터 생명주기 관리, 데이터 카테고리별 관리 책임자 지정 등 다양한 요소들 포함
- 데이터 거버넌스의 구성요소
    - 원칙 
        - 데이터 유지하고 관리하기 위한 지침 및 가이드
        - 보안, 품질기준, 변경관리 등
    - 조직
        - 데이터를 관리할 조직의 역할과 책임
        - 데이터 관리자, 데이터베이스 관리자, 데이터 아키텍트 등
    - 프로세스
        - 데이터 관리를 위한 활동과 체계
        - 작업 절차, 모니터링 활동, 측정 활동 등
- 데이터 거버넌스의 체계
    - 데이터 표준화
        - 데이터 표준 용어 설정 : 표준 단어 사전, 표준 도메인 사전, 표준 코드 등으로 구성되며, 각 사전 간 상호 검증이 가능한 점검 프로세스 포함
        - 명명 규칙 수립 : 필요시 언어별로 작성되어 기준 언어와의 연결 상태 유지
        - 메타 데이터 및 데이터 사전 구축 : 데이터의 원활한 활용을 위한 데이터 구조 체계 마련, 메타 엔티티 관계 다이어그램 등 제공
    - 데이터 관리 체계
        - 표준 데이터를 포함한 메타 데이터와 사전의 관리 원칙 수립 및 이에 근거한 항목별 상세 프로세스 수립
        - 데이터 관리와 운영을 위한 담당자 및 조직별 역할과 책임을 구체적으로 마련
        - 빅데이터의 경우 데이터 생명 주기 관리방안도 수립
    - 데이터 저장소 관리
        - 메타 데이터 및 표준 데이터를 관리학 위한 전사 차원의 저장소 구성
        - 저장소는 데이터 관리 체계 지원을 위한 Workflow 및 관리용 Applicatrion 지원
        - 관리 대상 시스템과의 인터페이스를 통한 통제 가능
        - 데이터 구조 변경에 따른 사전 영향 평가 등 수행
    - 표준화 활동
        - 데이터 거버넌스 체계를 구축한 후 표준 준수 여부를 주기적으로 점검
        - 데이터 거버넌스의 조직 내 안정적인 정착을 위한 계속적인 변화관리 및 주기적인 교육 진행
        - 지속적인 데이터 표준화 개선 활동을 통해 실용성 증대

6) 데이터 분석 교육 및 마인드 육성 체계

- 데이터 분석 교육 및 마인드 육성을 위한 변화 관리 필요성
    - 데이터 분석의 가치를 극대화하고 내재화하여 안정적인 추진기로 접어들기 위해 필요 : 새로운 체계를 도입하고자 할 경우 저항이나 기존 형태로 돌아가고자 하는 관성 발생
- 데이터 분석 문화 도입방안
    - 적극적 도입방안
        - 적합한 데이터 분석 과제 도출
        - 효율적인 데이터 분석 업무 수행을 위한 데이터 분석 조직 마련
        - 데이터 분석 마인드 형성을 위한 인력에 대한 지속적인 교육과 훈련 실시
        - 데이터 기반 의사결정을 할 수 있는 기업 문화를 정착시키기 위한 변화관리를 지속적으로 계획, 수행
    - 데이터 분석 교육방향
        - 단순한 도구 사용법 교육이 아닌 데이터 분석 역량을 확보하고 강화하는 방향으로 진행
        - 데이터 분석기획자에 대한 데이터 분석 큐레이션 교육 진행
        - 데이터 분석 실무자에 대한 데이터 분석 기법 및 도구 사용에 대한 교육 진행
        - 기존 업무 수행자를 대상으로 데이터 분석 기회 발굴과 시나리오 작성법 등을 교육
        - 조직 내 데이터 분석 기반 업무 수행 문화가 정착되도록 분석적인 사고 향상 교육 실시
        - 데이터를 바라보는 관점이나 데이터 분석과 활용 등이 하나의 문화로 받아들여지도록 유도

### 08. 데이터 분석 수준진단

1) 데이터 분석 수준진단 개요

- 분석 수준진단 필요성
    - 조직 경쟁력 강화를 위한 데이터 분석의 도입 여부와 활용을 위해 현 상태에 대한 명확한 점검 필요
    - 데이터 분석의 수준진단을 통해 데이터 분석 기반을 만들기 위해 무엇을 준비하고 더 보완해야 하는지 확인 가능하고, 데이터 분석의 유형이나 방향을 결정할 수 있음
- 분석 수준진단 목표
    - 각 조직이 현재 수행하고 있는 데이터 분석 수준을 명확히 이해하고, 수준진단 결과를 바탕으로 미래 목표수준 정의
    - 데이터 분석을 위한 기반이나 환경이 타사 대비 어느 정도 수준이고, 어느 영역에 선택과 집중을 해야 하는지, 무엇을 보완해야 하는지 등 개선 방안 도출

2) 분석 준비도 : 조직 내 데이터 분석 업무 도입을 목적으로 현재 수준을 파악하기 위한 진단방법

- 분석 준비도 원리
    - 총 6가지 영역을 대상으로 현재 수준 파악 : 각 진단 영역별로 세부 항목에 대한 수준까지 파악
    - 각 진단 결과 전체 요건 중 일정 수준 이상 충족하면 데이터 분석 업무를 도입
    - 만일 일정 수준 이상 충족되지 못하면 데이터 분석 환경 먼저 조성
- 데이터 분석 준비도 프레임워크
    - 분석 업무 파악
        - 발생한 사실 분석 업무
        - 예측 분석 업무
        - 시뮬레이션 분석 업무
        - 최적화 분석 업무
        - 분석 업무 정기적 개선
    - 인력 및 조직
        - 분석 전문가 직무 존재
        - 분석 전문가 교육 훈련 프로그램
        - 관리자들의 기본적 분석 능력
        - 전사 분석업무 총괄 조직 존재
        - 경영진 분석 업무 이해 능력
    - 분석 기법
        - 업무별 적합한 분석기법 사용
        - 분석 업무 도입 방법론
        - 분석기법 라이브러리
        - 분석기법 효과성 평가
        - 분석기법 정기적 개선
    - 분석 데이터
        - 분석업무를 위한 데이터 충분성
        - 분석업무를 위한 데이터 신뢰성
        - 분석업무를 위한 데이터 적시성
        - 비구조적 데이터 관리
        - 외부 데이터 활용 체계
        - 마스터데이터 관리(MDM)
    - 분석 문화
        - 사실에 근거한 의사결정
        - 관리자의 데이터 중시
        - 회의 등에서 데이터 활용
        - 경영진의 직관보다 데이터
        - 데이터 공유 및 협업 문화
    - IT 인프라
        - 운영시스템 데이터 통합
        - EAI, ETL 등 데이터유통체계
        - 분석 전용 서버 및 스토리지
        - 빅데이터 분석 환경
        - 통계 분석 환경
        - 비주얼 분석 환경

3) 분석 성숙도 모델 : 데이터 분석 능력 및 데이터 분석 결과 활용에 대한 조직의 성숙도 수준을 평가하여 현재 상태를 점검하는 방법

- 분석 성숙도 모델 특징
    - 비즈니스 부문, 조직 및 역량 부문, IT 부문 총 3개 부문을 대상으로 실시
    - 성숙도 수준에 따라 도입, 활용, 확산, 최적화 단계로 구분

4) 분석 수준진단 결과

- 분석 준비도 및 성숙도 진단 결과
    - 조직의 현재 데이터 분석 수준을 객관적으로 파악 가능
    - 타사의 데이터 분석 수준과 비교하여 데이터 분석 경쟁력 확보 및 강화를 위한 목표 수준 설정 가능
- 사분면 분석
    - 데이터 분석 관점에서 4가지 유형으로 데이터 분석 수준진단 결과 구분
    - 향후 고려해야 하는 데이터 분석 수준에 대한 목표나 방향을 정의할 수 있으며, 유형별 특성에 따라 개성방안 수립

## SECTION 02. 분석 작업 계획

### 01. 분석 잡업 개요

1) 데이터 처리 영역 : 데이터 분석을 위한 기초 데이터를 정의하고 수집 및 저장, 분석하기 수월하도록 물리적인 환경 제공
- 데이터 소스 : 기업 내 각 부서나 서비스별 적재되고 있는 내부 데이터와 다른 기업이나 공공 데이터 등 외부 데이터 있음
- 데이터 수집 : 사용자로부터 데이터를 직접 입력받거나 로그수집기, 크롤링, 센서네트워크 등을 통해 데이터 수집
- 데이터 저장 : 데이터를 유형별로 나눠 최적의 설계를 하여 데이터 스토리지에 저장
- 데이터 처리 : 저장된 대용량의 데이터를 신속하고 정확하게 처리하기 위하여 실시간 처리 및 분산 처리 등 시도

2) 데이터 분석 영역 : 저장되어 있는 데이터를 추출하여 분석 목적과 방법에 맞게 가공한 후, 데이터 분석을 직접 수행하고 그 결과 표현하는 영역
- 데이터 분석
    - 도메인 이슈 도출
        - 분석 대상 과제 현황을 파악하고 개선과제 정의
        - 문제의 주요 이슈별로 개선방향 도출, 개선방안을 수립하며, 빅데이터 요건 정의서 작성
    - 분석목표 수립
        - 빅데이터 요건 정의서를 토대로 개선방향에 맞는 현실적인 분석목표 수립
        - 데이터 관련 정보, 분석 타당성 검토, 성과측정 방법 등을 포함한 분석목표정의서 작성
    - 프로젝트 계획 수립
        - 사전에 책정된 자원과 예산, 기간 등을 고려하여 분석 프로젝트 계획 수립
        - 분석목표정의서, 프로젝트 소요비용 배분계획을 바탕으로 작업분할구조도(WBS)를 작성
    - 보유 데이터 자산 확인 : 분석목표와 프로젝트 계획을 기반으로 현재 보유 중인 데이터의 품질이나 규모, 유형 등을 확인하고 법률적 이슈나 제약사항 등 검토
- 데이터 표현
    - 빅데이터 분석 결과 시각화 : 다양한 분석 및 시각화 도구를 활용하여 분석 결과 시각화

### 02. 데이터 확보 계획

1) 데이터 확보를 위한 사전 검토사항

- 필요 데이터의 정의
    - 분석 목적에 맞는 데이터를 정의하고, 필요한 데이터를 확보할 수 있는지 확인하여야 하며, 확보할 수 없다면 대안을 함께 고려
    - 기업 내부 및 외부 공공기관이나 협력관계의 타 기업 담당자, 전문가 등 이해관계자들과 확보 가능한 데이터의 목록과 기대효과 등을 작성
- 보유 데이터의 현황 파악 : 사전에 정의한 데이터의 존재 여부와 분석 품질을 보장할 만큼 데이터 품질이 우수한지, 충분한 양이 존재하는지 확인
- 분석 데이터의 유형
    - 분석 데이터 확보를 위해 수집 대상 데이터의 유형을 고려
    - 어떤 데이터를 어떤 기법을 이용하여 분석할 것인지 수립된 계획에 따라 데이터의 유형을 선택하고 변수 정의
- 편향되지 않고 충분한 양의 데이터 규모
    - 데이터 분석 기법에 따라 훈련 데이터센, 검증 데이터셋, 테스트 데이터셋 필요
    - 신뢰성 높은 데이터 분석 모형 개발과 정확한 데이터 분석을 위해 3가지 데이터 세트로 나누어 사용할 만큼 충분한 데이터 확보되어야 함
- 내부 데이터의 사용
    - 필요 데이터에 대한 데이터 목록(변수 명칭, 설명, 형태, 기간, 용량, 권한 등) 작성
    - 필요 데이터에 대한 관련 법률이나 보안적인 요소들을 확인하고, 개인정보일 경우 비식별 조치방안 함께 고려
- 외부 데이터의 수집
    - 필요 데이터에 대한 데이터 목록을 데이터를 보유한 기업의 이름과 데이터 제공 방법(Open API, 복제 등)까지 고려하여 작성
    - 필요 데이터의 수집이 관련 법률이나 제도상 제약이 없는지 검토

2) 분석에 필요한 변수 정의 : 데이터 분석 요건에 따라 도출된 활용 시나리오에 적합한 데이터의 유형 및 분석 변수 정의

- 데이터 수집 기획
    - 데이터 수집 기법을 활용하여 필요 데이터를 배치 자동화로 수집
        - 데이터 수집 타깃 시스템 또는 사이트 선별
        - 수집 대상 화면, 텍스트를 위해 인덱스 생성 기획
        - 대상 시스템별 데이터 수집을 위한 크롤러를 준비하고 저장소 기획
        - 크롤링 주기, 대상 범위를 확정하고 데이터 수집 기획
    - 데이터 거래소, 공공 데이터에 적재된 분야별 데이터를 분류하고 선별
        - 검색한 공공 데이터 중 분석 대상이 되는 도메인의 우선순위 정의
        - 필요한 데이터를 다운로드받아 저장할 수 있도록 계획
        - 저장한 데이터를 NoSQL 데이터에 적재하고 정제할 수 잇도록 설계
- 분석 변수 정의
    - 빅데이터의 특징을 고려하여 분석 변수 생성 기획 : 상관관계 분석을 위한 데이터 연속성 범주 등을 고려하여 분석 변수 정의
    - 분석 변수 유형과 형성 알고리즘을 이용하여 분석 유형 도출 : 변수의 분포를 구별하는 정도에 따라 순수도 또는 불순도에 의해서 측정 구간별 순수도를 가장 높이는 분석 변수 도출

3) 분석 변수 생성 프로세스 정의 : 분석 대상에 대해 객관적으로 인식하고 논리적 인과관계 분석 및 데이터 간 상관관계 분석을 위한 분석 변수 생성 프로세스 정의

- 객관적 사실 기반의 문제 접근 : 명확한 문제 인식을 위하여 분석적이고 가정에 의한 접근 방법과 함께 무엇이 문제인지를 파악하여 객관적 관찰 데이터 유형 식별
- 데이터의 상관 분석 : 빅데이터 분석 대상의 연관성 분석을 통해 데이터 집합 간 통계적 관련성을 분석할 수 있는 변수를 생성하고 변수의 척도를 분류
- 프로토타입을 통한 분석 변수 접근 : 의미 있는 분석 변수를 생성하기 위하여 프로토타이핑 접근법을 통해 결과를 확인하며, 반복적으로 개선하여 필요한 데이터를 식별하고 구체화하여 비정형 데이터가 갖는 문제 해소

4) 생성된 분석 변수의 정제를 위한 점검항목 정의 : 분석 기획 단계에서 도출된 문제 인식, 해결을 위한 개념적 대안 설계를 통해 도출된 데이터에 대해 가용성을 평가하고 점검항목 정의

- 분석 변수 점검의 필요성
    - 데이터의 가용성과 적정성이 부족할 경우 문제 해결 및 활용 시나리오 적용을 통해 가치 있는 결과를 도출하기 어려움
    - 실행 전 분석 변수를 논리적 지표에 따라 점검
- 분석 변수 점검항목 정의
    - 데이터 수집
        - 데이터 적정성 : 문제 해결에 적절한 분석 변수인가?
        - 데이터 가용성 : 수집 가능한 데이터인가?
        - 대체 분석 데이터 유무 : 수집 불가능한 데이터인 경우 간접적으로 연관성 있는 데이터로 대체 가능한가?
    - 데이터 적합성
        - 데이터 중복 : 중복이나 노이즈 제거, 데이터값 존재 유무 등 기초 데이터 클렌징 수행 가능한가?
        - 분석 변수별 범위 : 분석 변수별 측정될 수 있는 min/max를 확인하였는가?
        - 분석 변수별 연관성 : 수집된 데이터 간 충분 간격으로 연관성이 있는가?
        - 데이터 내구성 : 데이터 노이즈, 왜곡이 발생하였을 때 예측 성능을 보장할 수 있는가?
    - 특징 변수
        - 특징 변수 사용 : 분석 변수 중 바로 특징 변수로 사용할 수 있는 가능성이 있는가?
        - 변수 간 결합 가능 여부 : 분석 변수를 결합하여 교차 검증을 할 수 있는가?
    - 타당성
        - 편익/비용 검증 : 분석 비용관 분석 후 결과가 추가적 매출, 수익 등에 기여할 수 있는가?
        - 기술적 타당성 : 다양한 분석 툴을 활용할 수 있는 분석 변수를 도출하였는가?
    
5) 생성된 분석 변수의 전처리 방법 수립 : 데이터 정제를 위한 점검항목 정의 후 이에 맞게 논리적 모형 설계를 위한 데이터 전처리 방법 수립

- 데이터 전처리 수행
    - 다양한 비즈니스 도메인에서 추출한 정형, 반정형, 비정형 데이터를 분석 및 처리에 적합한 데이터 형태로 조작
    - 데이터 정제, 통합, 축소, 변환을 반복적으로 수행하여 분석 변수로 활용하는 방안 수립 가능

|처리 기법|내용|
|데이터 정제|결측값을 채우거나 이상치를 제거하는 과정을 통해 데이터의 신뢰도를 높이는 작업|
|데이터 통합|다수의 정제된 데이터를 통합하여 표현하는 작업|
|데이터 축소|데이터 집합의 크기는 더 작지만 분석 결과는 같은 데이터 집합으로 만드는 작업|
|데이터 변환|데이터 마이닝의 효율을 높이기 위한 변환 및 변형 작업|

- 빅데이터 분석 프로세스 수행
    - 다양한 업무와 도메인이 포함되어 있어 완전히 자동화하여 처리하는 것은 어려움
    - 데이터 전처리 과정은 정제와 통합을 통해 약 60~80% 처리

6) 생성 변수의 검증 방안 수립

- 분석 변수의 데이터 검증 방안 수립
    - 모든 개별 데이터에 대한 타당성 보장보다는 빅데이터 개념 및 특성 측면에서 관리되어야 하는 항목과 수준에 대해 품질 검증 정의
        - 대량 데이터
            - 데이터 사용자 오류는 무시
            - 데이터 타당성에 치명적인 예외 상황만 탐지
        - 정밀 데이터
            - 개별 데이터에 대한 타당성 검증은 환경 및 상황에 따라 판단
            - 데이터 전체가 나타내는 의미를 중심으로 검증 기준 정의
        - 데이터 출처 불명확 : 명확한 목적이나 사전 통제 없이 생성된 데이터에 대한 별도 품질 기준 정의
    - 빅데이터 품질 관리 및 검증은 정확성보다는 데이터의 양이 충분한지에 대한 충분성 개념하에 조직의 비즈니스 영역 및 목적에 따라 검증
        - 정확성 : 데이터 사용 목적에 따라 데이터 정확성의 기준 상이하게 적용
        - 완전성 : 필요한 데이터인지 식별하는 수준으로 품질 요소 적용
        - 적시성
            - 소멸성이 강한 데이터에 대한 품질 기준 판단
            - 웹로그 데이터, 트윗 데이터 등 지속적으로 생성 소멸하는 데이터에 대한 품질 기준 수립
        - 일관성 : 동일한 데이터의 경우에도 사용 목적에 따라 데이터의 의미가 달라지기 때문에 분석 요건에 따른 검증 요소 적용
- 데이터 검증 체계 수립
    - 수집한 데이터의 출처가 명확한지 검증
    - 중복된 데이터가 존재하는지, 정보 활용에 컴플라이언스 이슈가 없는지 데이터 관리 대상 선별 검증
    - 데이터의 다양성이 확보되었는지, 데이터셋이 충분한지 검증
    - 주요 품질 지표의 조건을 만족하는지, 분석, 검증, 테스트 데이터가 분리되어 있는지 주요 품질 지표를 분석 및 검증

### 03. 분석 절차와 작업 계획

1) 분석 절차 : 데이터 분석의 시발점이 되는 문제 인식에서부터 시작하여 데이터를 확보하고 분석하여 결과를 도출 및 제시하는 단계까지의 일반적인 과정을 정형화한 프로세스

- 분석 절차의 특징
    - 데이터 분석을 수행하기 위한 기본적인 과정 명시
    - 분석 방법론을 구성하는 최소 요건
    - 상황에 따라 단계를 추가할 수도 있으며 생략 가능
- 일반적인 분석 절차
    - 문제 인식
        - 문제를 인식하고 분석 목적을 명확하게 정의
        - 분석 주제는 가설 형태 또는 결과 해석을 중심으로 할 수 있음
    - 연구조사
        - 문제 해결을 위한 각종 문헌을 조사하고 내용을 바탕으로 문제에 대한 해결방안 정의
        - 중요한 요인이나 변수들을 파악
    - 모형화
        - 복잡한 문제를 논리적이면서도 단순화하는 과정
        - 많은 변수가 포함된 현실 문제를 특징적 변수로 정의
        - 문제를 변수들 간의 관계로 정의
    - 데이터 수집
        - 데이터 수집 또는 변수를 측정하는 과정
        - 기존 데이터 활용이 불가능한 경우 추가적인 데이터 수집 고려
    - 데이터 분석
        - 수집된 데이터로부터 인사이트를 발굴
        - 수집된 데이터로부터 변수들간의 관계 분석
    - 분석 결과 제시
        - 변수들 간 인과관계나 상관관계를 포함한 분석 결과를 제시하고 공유
        - 표, 그림, 차트, 그래프 등을 활용하여 시각화
- 분석 절차 적용 시 고려사항
    - 문제에 대한 구체적 정의가 가능하고, 필요 데이터를 보유하고 있으며, 분석역량을 갖추고 있다면 통계 기반의 전통적 데이터 분석 수행
    - 문제에 대한 구체적 정의가 없다면 데이터 마이닝 기반으로 데이터를 분석하여 인사이트를 발굴하거나 일단 데이터 분석을 시도한 후 겨로가를 확인해 가면서 반복적으로 개선 결과 도출 가능

2) 작업 계획 : 분석 절차에 따라 데이터 분석 업무를 수행하기 위한 전반적인 작업 내용들을 세부적으로 정의하는 과정

- 분석 작업 계획 수립
    - 프로젝트 소요비용 배분
        - 주어진 시스템 및 데이터 환경을 고려하여 현실성 있는 계획이 되도록 프로젝트 일정 수립
        - 사전에 작성해 놓은 데이터 분석목표정의서의 내용이 모두 반영될 수 있도록 함
    - 프로젝트 작업분할구조 수립 : 데이터 분석목표정의서와 프로젝트 소요비용 배분 계획을 참고하여 데이터 분석 절차에 맞게 수립
    - 프로젝트 업무 분장 계획 및 배분
        - 배분된 인건비를 기준으로 단계별 인원 투입 계획을 수립하고 역할별로 작성해야 하는 필수 산출물을 정의
        - 프로젝트 유관부서 리더들과 프로젝트 참여 인원을 중심으로 프로젝트 평가위원회를 구성
        - 상황에 따라 외부 자문 위원을 참여
- 분석 작업 계획 수립을 위한 작업분할구조(WBS)
    - 데이터 분석과제 정의
        - 데이터 분석목표정의서를 기준으로 프로젝트 전체 일정에 맞춰 사전에 준비
        - 각 단계별 필요 산출물과 보고서 작성 시기, 세부 일정 등 정리
    - 데이터 준비 및 탐색
        - 데이터 엔지니어가 데이터를 수집하고 정리하는 일정을 수립
        - 데이터 분석가가 분석에 필요한 데이터들로부터 변수 후보를 탐색하고 최종 산출물을 도출하는 일정 수립
        - 데이터 분석 가설을 세우고 유의미한 검정을 수행하는 일정을 포함
    - 데이터 분석 모델링 및 검증
        - 실험방법 및 절차를 구분하고 검증하는 내용과 수행일정을 상세하게 수립
        - 데이터 분석 모델링 작업이 1회 이상 수행되므로 검증일정 고려하여 세부 일정 수립
    - 산출물 정리
        - 데이터 분석 단계별 산출물을 정리, 모델링 과정에서 개발된 분석 스크립트를 최종 산출물로 정리
        - 전체 일정에서 산출물 정리 과정을 반드시 포함
        
3) 분석목표 정의서 : 문제의 개선방향에 맞는 현실적인 분석목표를 수립하여 필요한 데이터에 대한 정보나 분석 타당성 검토 및 성과측정 방법 등을 정리한 정의서

- 분석목표정의서 구성요소
    - 원천 데이터 조사
        - 데이터 정보 : 데이터 축적 기간, 획득 주기, 테이블 스키마, 메타 데이터를 확인
        - 데이터 수집 난이도
            - 데이터 수집 및 정제 과정, 시기와 방법 확인
            - 데이터 수집 난이도가 높을 경우 데이터 활용 재고
    - 분석 방안 및 적용 가능성 판단
        - 개선 목표와 현시점의 분석 목표 간 차이를 고려하여 분석 목표를 조정하거나 상황에 따라 우선순위 조정
        - 분석 목표에 부합한 데이터 분석 기법이 있더라도 현재 적합한 분석 환경이 구축되지 않았다면 분석 목표 조정
    - 성과평가 기준
        - 정성적 평가
            - 분석 기법이나 기술의 활용 가능성 평가
            - 신규 데이터나 외부 데이터의 활용 가능성 평가
            - 세분화나 군집화를 통해 집단 선정
            - 이 외 관련 시스템별로 정성적 요소 평가
        - 정량적 평가
            - 기존 방법 대비 효과의 증감 비율 평가
            - 유효한 가설의 수나 목표 대비 증감 비율 평가
            - 데이터 모형의 정확도를 측정하여 평가
            - 기타 분석 특성에 따른 자체 KPI에 의한 성과 측정
- 분석목표정의서 작성 방법
    - 분석 목적을 설정하고 이를 달성하기 위한 세부 목표 수립
    - 필요한 데이터를 정의하고, 분석 방법과 데이터 수집 및 분석 난이도, 수행 주기, 분석 결과에 대한 검증 기준 설계
    - 도메인 이슈 도출을 통한 개선 방향을 토대로 목표 수준 정리

### 04. 분석 프로젝트 관리

1) 분석 프로젝트 : 과제 형태로 도출된 분석 기회를 프로젝트화하여 그 가치를 증명하기 위한 수단

- 특징
    - 데이터 영역과 비즈니스 영역에 대한 이해와 더불어 지속적인 반복이 요구되는 분석 프로세스의 특성을 이해하여 프로젝트 관리방안 수립
    - 지속적인 개선 및 변경을 염두에 두고 프로젝트 기한 내에 가능한 최선의 결과를 도출할 수 있도록 프로젝트 구성원들과 협업 필요
- 추가적 속성 : 데이터를 다루면서 분석 모형을 생성하는 프로젝트 특성상 아래 표의 추가적인 중점 관리 영역 고려
    - 데이터 크기 : 데이터가 지속적으로 생성되어 증가하는 점 고려
    - 데이터 복잡도
        - 정형, 비정형 데이터와 다양한 시스템에 산재되어 있는 원천 데이터들을 통합하는 진행 필요
        - 데이터에 잘 적용될 수 있는 분석 모형의 선정 등을 사전에 고려
    - 속도
        - 분석 결과가 도출되어 이를 활용하는 시나리오 측면에서의 속도까지 고려
        - 프로젝트 수행 시 분석 모형의 성능과 속도를 고려한 개발과 테스트 수행 고려
    - 분석 모형의 복잡도
        - 분석 모형의 정확도와 복잡도는 Trade off 관계
        - 분석 모형이 복잡할수록 정확도는 상승하지만 해석이 어려워지므로 이에 대한 기준을 정의하고 최적 모형을 탐색
    - 정확도와 정밀도
        - 분석 결과를 활용하는 측면에서는 Accuracy가 중요
        - 분석 모형의 안정성 측면에서는 Precision이 중요
        - Accuracy와 Precision은 Trade off 경우가 많음
- 분석가의 역할 : 분석가는 데이터 영역과 비즈니스 영역의 중간에서 현황을 이해하고 분석 모형을 통한 조율을 수행하는 조정자의 역할과 분석 프로젝트 관리 역할 수행

2) 분석 프로젝트 관리

- 효율적인 데이터 분석 수행을 위한 필요성 : 범위, 일정, 품질, 이슈 및 리스크, 의사소통 등 영역별로 고려해야 하는 요소가 많아 체계적 관리가 필요
- 분석 프로젝트의 관리 방안
    - 분석 프로젝트는 데이터 분석이 갖는 기본 특성(5V)을 살려 프로젝트 관리 지침을 만들어 기본 가이드로 활용
    - 프로젝트 관리 영역에 대한 주요한 사항들은 체크포인트 형태로 관리되어야 함

3) 분석 프로젝트의 영역별 주요 관리 항목

- 범위 관리
    - 분석 기획 단계에서 명시한 프로젝트의 범위는 분석을 수행하면서 데이터의 형태와 양 또는 적용되는 모형의 알고리즘에 따라 빈번하게 변경되곤 하며 이것은 프로젝트를 지연시키는 중대한 사유가 됨
    - 분석의 최종 결과물이 분석 보고서 형태인지 시스템인지에 따라 투입되는 자원과 범위가 크게 달라지므로 사전에 충분히 고려
- 일정 관리
    - 분석 프로젝트는 초기에 의도했던 모형이나 결과가 쉽게 나오는 경우가 흔치 않으며, 지속적으로 반복하는 과정에서 많은 시간 소모
    - 분석 결과의 품질을 보장한다는 전제하에 Time Boxing 기법으로 일정을 관리하는 것이 필요
- 원가 관리
    - 외부 데이터를 활용하여 데이터 분석을 수행하는 경우 데이터 구입 및 수집을 위해 많은 비용이 소모될 수 있으므로 사전에 충분한 조사 필요
    - 프로젝트를 수행하는 과정에서 목표한 결과를 달성하기 위해 오픈 소스 도구를 사용하지 않고 고가의 사용 도구를 사용하게 될 경우 비용 증가
- 품질 관리
    - 분석 프로젝트의 수행 결과에 대한 품질목표를 사전협의를 통해 수립하고 통제 하여야 함
    - 프로젝트 품질은 품질관리계획과 품질통제 및 품질보증으로 구성되어 있으며, 이를 잘 나누어 수행하여야 함
- 통합 관리 : 프로젝트 관리 프로세스들을 통합적으로 운영될 수 있도록 관리하여야 함
- 조달 관리
    - 상황에 따라 분석 프로젝트 목적에 적합한 범위 내에서 외부에 아웃소싱을 수행
    - PoC와 같이 지속성이 보장되지 않은 프로젝트는 인프라 구매보다 클라우드와 같은 대여방식을 고려해 볼 필요가 있음
- 인적자원 관리
    - 분석 프로젝트는 인적자원과 데이터가 핵심이므로, 프로젝트 수행 전 전문인력 확보와 고용유지 방안을 검토하여야 함
    - 전문인력의 효율적인 운영을 위해 핵심인재의 전문분야와 보유역량 및 수준 등을 관리하고, 프로젝트별 투입 시점과 피로도 등을 종합적으로 관리
- 위험 관리 : 분석 프로젝트 진행 과정에서 발생할 수 있는 위험을 식별하고, 위험을 분석하여 대응방안 수립
- 의사소통 관리 : 프로젝트의 원활한 진행을 위한 다양한 의사소통 채널과 모든 이해관계자가 분석 결과를 공유할 수 있도록 시각화와 같은 방안 마련
- 이해관계자 관리 : 분석 프로젝트에 영향을 미치는 이해관계자와 참여하는 데이터, 분석, 비즈니스, 시스템 등의 전문가들을 잘 관리하여야 함