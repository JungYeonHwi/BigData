# 빅데이터 분석 기획

## SECTION 01. 빅데이터 개요 및 활용

### 01. 데이터와 정보

1) 데이터의 정의 : 추론과 추정의 근거를 이루는 사실

2) 데이터의 특징 : 단순한 객체로도 가치가 있으며 다른 객체와의 상호관계 속에서 더 큰 가치를 가짐

3) 데이터의 구분

- 정량적 데이터 : 주로 숫자로 이루어진 데이터
- 정성적 데이터 : 문자와 같은 텍스트로 구성되며 함축적 의미를 지니고 있는 데이터

||정량적 데이터|정성적 데이터|
|---|---|---|
|유형|정형 데이터, 반정형 데이터|비정형 데이터|
|특징|여러 요소의 결합으로 의미 부여|객체 하나가 함축된 의미 내포|
|관점|주로 객관적 내용|주로 주관적 내용|
|구성|수치나 기호 등|문자나 언어 등|
|형태|데이터베이스, 스프레드시트 등|웹 로그, 텍스트 파일 등|
|위치|DBMS, 로컬 시스템 등 내부|웹사이트, 모바일 플랫폼 등 외부|
|분석|통계 분석 시 용이|통계 분석 시 어려움|

4) 데이터의 유형

- 정형 데이터 : 정해진 형식과 구조에 맞게 저장되도록 구성된 데이터이며, 연산 가능
- 반정형 데이터 : 데이터의 형식과 구조가 비교적 유연, 스키마 정보를 데이터와 함께 제공하는 파일 형식의 데이터, 연산 불가능
- 비정형 데이터 : 구조가 정해지지 않은 대부분의 데이터, 연산 불가능

5) 데이터의 근원에 따른 분류

- 가역 데이터 : 생산된 데이터의 원본으로 일정 수준 환원이 가능한 데이터
- 불가역 데이터 : 생산된 데이터의 원본으로 환원이 불가능한 데이터

6) 데이터의 기능 : 데이터를 기반으로 한 암묵지와 형식지의 상호작용 중요

- 암묵지 : 어떠한 시행착오나 다양하고 오랜 경험을 통해 개인에게 체계화되어 있으며, 외부에 표출되지 않은 무형의 지식으로 전달과 공유 어려움
- 형식지 : 형상화된 유형의 지식으로 전달과 공유 쉬움

7) 지식창조 매커니즘

- 공통화 : 서로의 경험이나 인식을 공유하며 한 차원 높은 암묵지로 발전
- 표출화 : 암묵지가 구체화되어 외부(형식지)로 표현
- 연결화 : 형식지를 재분류하여 체계화
- 내면화 : 전달받은 형식지를 다시 개인의 것으로 만듦

8) 데이터, 정보, 지식, 지혜 : 지혜 c 지식 c 정보 c 데이터

### 02. 데이터베이스

1) 데이터베이스의 정의 : 체계적이거나 조직적으로 정리되고 전자식 또는 기타 수단으로 개별적으로 접근할 수 있는 독립된 저작물, 데이터 또는 기타 소재의 수집물

2) 데이터베이스 관리 시스템(DBMS) : 데이터베이스를 관리하며 응용 프로그램들이 데이터베이스를 공유하며 사용할 수 있는 환경을 제공하는 소프트웨어

- SQL
    - 데이터베이스에 접근할 때 사용하는 언어
    - 단순한 질의 기능뿐만 아니라 데이터 정의와 조작 기능을 갖춤
    - 테이블 단위로 연산을 수행하며 초보자들도 비교적 쉽게 사용 가능

3) 데이터베이스의 특징

- 통합된 데이터
- 저장된 데이터
- 공용 데이터
- 변화 데이터

4) 데이터베이스의 활용

- OLTP : 호스트 컴퓨터와 온라인으로 접속된 여러 단말 간 처리 형태의 하나로 데이터베이스의 데이터를 수시로 갱신하는 프로세싱
- OLAP : 정보 위주의 분석 처리를 하는 것으로, OLTP에서 처리된 트랜잭션 데이터를 분석해 제품의 판매 추이, 구매 성향 파악, 재무 회계 분석 등을 프로세싱

5) 데이터 웨어하우스(DW) : 사용자의 의사결정에 도움을 주기 위하여 기관시스템의 데이터베이스에 축적된 데이터를 공통의 형식으로 변환해서 관리하는 데이터베이스

### 03. 빅데이터 개요

1) 빅데이터의 등장과 변화

- 빅데이터의 등장 배경 : 디지털화, 저장 기술, 인터넷 보급, 모바일 혁명, 클라우드 컴퓨팅 등 관련 기술이 빠르게 발전
- 빅데이터의 등장으로 인한 변화
    - 데이터 처리 시점이 사전 처리에서 사후 처리로 이동
    - 데이터 처리 범주가 표본조사에서 전수조사로 확대
    - 데이터의 가치 판단 기준이 질보다 양으로 그 중요도가 달라짐
    - 데이터를 분석하는 방향이 이론적 인과관계 중심에서 단순한 상관관계로 변화되는 경향

2) 빅데이터의 특징 : 3V + 2V

|협의|특징|내용|
|---|---|---|
|3V|규모(Volume)|데이터의 양이 급격하게 증가|
|3V|유형(Variety)|데이터의 종류와 근원 확대|
|3V|속도(Velocity)|데이터 수집과 처리 속도의 변화|
|2V|품질(Veracity)|데이터의 신뢰성, 정확성, 타당성 보장이 필수|
|2V|가치(Value)|대용량의 데이터 안에 숨겨진 가치 발굴 중요|

3) 빅데이터의 활용

|구성 요소|내용|
|---|---|
|자원 (빅데이터)|정형, 반정형, 비정형 데이터를 실시간으로 수집|
|기술 (빅데이터플랫폼, AI)|분산 파일 시스템을 통해 대용량 데이터를 분산 처리|
|인력 (알고리즈미스트, 데이터사이언티스트)|통계학, 수학, 컴퓨터 공학, 경영학 분야 전문지식을 갖춤

### 04. 빅데이터의 가치

1) 빅데이터의 기능과 효과

- 빅데이터는 이를 활용하는 기존 사업자에게 경쟁 우위 제공
    - 새롭게 시장에 진입하려는 잠재적 경쟁자에게는 진입장벽과도 같음
    - 고객 세분화와 맞춤형 개인화 서비스를 제공
- 빅데이터는 알고리즘 기반으로 의사결정을 지원하거나 이를 대신
- 빅데이터는 투명성을 높여 R&D 및 관리 효율성을 제고

2) 빅데이터의 가치 측정의 어려움

- 데이터 활용 방식 : 데이터를 재사용하거나 재결합, 다목적용 데이터 개발 등이 일반화되면서 특정 데이터를 누가, 언제, 어디서 활용 할지 알 수 없기에 그 가치 측정 어려움
- 가치 창출 방식 : 데이터는 어떠한 목적을 갖고서 어떻게 가공하는가에 따라 기존에 없던 가치를 창출할 수 있어 사전에 그 가치 측정 어려움
- 분석 기술 발전 : 데이터는 지금의 기술 상황에서는 가치가 없어 보일지라도 새로운 분석 기법이 등장할 경우 큰 가치를 찾아낼 수 있으므로 당장 그 가치 측정 어려움
- 데이터 수집 원가 : 데이터는 달성하려는 목적에 따라 수집하거나 가공하는 비용이 상황에 따라 달라질 수 잇어 그 가치 측정 어려움

### 05. 데이터 산업의 이해

1) 데이터 산업의 진화

- 데이터 처리 시대 : 컴퓨터 프로그래밍 언어를 이용하여 대규모 데이터를 빠르고 정확하게 처리할 수 있게 되었으며 결과는 파일 형태로 보관
- 데이터 통합 시대 : 데이터 모델링과 데이터베이스 관리 시스템이 등장
- 데이버 분석 시대 : 대규모 데이터를 보관하고 관리할 수 있는 하둡, 스파크 등의 빅데이터 기술 등장
- 데이터 연결 시대 : 기업 또는 기관, 사람, 사물 등 모든 것이 항상 그리고 동시에 둘 이상의 방식으로 연결되어 데이터를 주고 받음
- 데이터 권리 시대 : 데이터의 원래 소유자인 개인이 자식의 데이터에 대해 권리를 보유하고 있으며 스스로 행사할 수 있어야 한다는 마이데이터 등장


## SECTION 02. 빅데이터 기술 및 제도

### 01. 빅데이터 플랫폼

1) 정의 : 빅데이터 수집부터 저장, 처리, 분석 등 전 과정을 통합적으로 제공하여 그 기술들을 잘 사용할 수 있도록 준비한 환경

2) 빅데이터 플랫폼의 등장 배경

- 비즈니스 요구사항 변화
- 데이터 규모의 처리 복잡도 증가
- 데이터 구조의 변화와 신속성 요구
- 데이터 분석 유연성 증대

2) 빅데이터 플랫폼의 기능

- 컴퓨팅 부하 발생
- 저장 부하 발생
- 네트워크 부하 발생

3) 빅데이터 플랫폼의 조건 : 서비스 사용자와 제공자 어느 한쪽에 치우쳐서는 안 되며 모두가 만족할 수 잇는 환경을 제공해야 함

### 02. 빅데이터 처리기술

1) 빅데이터 처리과정과 요소기술

- 생성
    - 데이터베이스나 파일 관리 시스템과 같은 내부 데이터가 존재
    - 인터넷으로 연결된 외부로부터 생성된 파일이나 데이터 존재
- 수집
    - 크롤링을 통해 데이터 원천으로부터 데이터 검색하여 수정
    - ETL을 통해 소스 데이터로부터 추출, 변환, 적재
    - 단순한 수집이 아니라 검색 및 수집, 변환 과정 모두 포함
    - 로그 수집기나, 센서 네트워크 및 Open API 등을 활용
- 저장(공유)
    - 저렴한 비용으로 데이터를 쉽고 빠르게 많이 저장
    - 정형 데이터뿐만 아니라 반정형, 비정형 데이터도 포함
    - 병렬 DBMS나 하둡, NoSQL 등 다양한 기술 사용
    - 시스템 간의 데이터를 서로 공유
- 처리
    - 데이터를 효과적으로 처리하는 기술이 필요한 단계
    - 분산 병렬 및 인 메모리 방식으로 실시간 처리
    - 대표적으로 학둡의 맵리듀스를 활용
- 분석
    - 데이터를 신속하고 정확하게 분석하여 비즈니스에 기여
    - 특정 분야 및 목적의 특성에 맞는 분석 기법 선택이 중요
    - 통계분석, 데이터 마이닝, 텍스트 마이닝, 기계학습 방법 등
- 시각화
    - 처리 및 분석 결과를 표, 그래프 등을 이용해 쉽게 표현하고 탐색이나 해석에 활용
    - 정보 시각화 기술, 시각화 도구, 편집 기술, 실시간 자료 시각화 기술로 구성

2) 빅데이터 수집

- 크롤링 : 무수히 많은 컴퓨터에 분산 저장되어 있는 문서를 수집하여 검색 대상의 색인으로 포함시키는 기술
- 로그 수집기 : 조직 내부에 있는 웹 서버나 시스템의 로그를 수집하는 소프트웨어
- 센서 네트워크 : 유비쿼터스 컴퓨팅 구현을 위한 초경량 저전력의 많은 센서들로 구성된 유뮤선 네트워크
- RSS Reader/Open API : 데이터의 생산, 공유, 참여할 수 있는 환경인 웹 2.0을 구현하는 기술
- ETL 프로세스 : 데이터의 추출, 변환, 적재의 약어, 다양한 원천 데이터를 취합해 추출하고 공통된 형식으로 변환하여 적재하는 과정
    - 데이터 추출 : 원천 데이터로부터 적재하고자 하는 데이터 추출
    - 데이터 변환
        - 추출한 데이터를 변환하고 균질화하여 정제
        - 정제한 데이터를 적재하고자 하는 데이터 웨어하우스 구조에 맞게 변환
        - 통합하는 제약 조건 및 비즈니스 규칙에 따라 필터링이나 확인 작업
    - 데이터 적재 : 변환된 데이터를 데이터 웨어하우스에 적재

3) 빅데이터 저장

- NoSQL(Not-only SQL)
    - 전통적인 관계형 데이터베이스와는 다르게 데이터 모델을 단순화하여 설계된 비관계형 데이터베이스로 SQL을 사용하지 않는 DBMS와 데이터 저장장치
    - 기존의 RDBMS 트랜잭션 속성인 원자성, 일관성, 독립성, 지속성을 포기
    - 데이터 업데이트가 즉각적으로 가능한 데이터 저장소
    - Cloudata, Hbase, Cassandra, MongoDB 등
- 공유 데이터 시스템
    - 일관성, 가용성, 분할 내성 중에서 최대 두 개의 속성만 보유 (CAP 이론)
    - 분할 내성을 취하고 일관성과 가용성 중 하나를 포기하여 일관성과 가용성을 모두 취하는 기존 RDBMS보다 높은 성능과 확장성을 제공
- 병렬 데이터베이스 관리 시스템
    - 다수의 마이크로프로세서를 사용하여 여러 디스크에 질의, 갱신, 입출력 등 데이터베이스 처리를 동시에 수행하는 시스템
    - 확장성을 제공하기 위해 작은 단위의 동작으로 트랜잭션 적용 필요
    - VoltDB, SAP HANA, Vertica, Greenplum, Netezza가 대표적
- 분산 파일 시스템
    - 네트워크로 공유하는 여러 호스트의 파일에 접근할 수 있는 파일 시스템
    - 데이터를 분산하여 저장하면 데이터 추출 및 가공 시 빠르게 처리
    - GFS, HDFS, 아마존 S3 파일 시스템이 대표적
- 네트워크 저장 시스템
    - 이기종 데이터 저장 장치를 하나의 데이터 서버에 연결하여 총괄적으로 데이터를 저장 및 관리하는 시스템
    - SAN, NAS가 대표적

4) 빅데이터 처리

- 분산 시스템과 병렬 시스템
    - 분산 시스템
        - 네트워크상에 분산되어 있는 컴퓨터를 단일 시스템인 것처럼 구동하는 기술
        - 분산 시스템에 속한 각 노드는 독립된 시스템
        - 독립 컴퓨터의 집합으로 만들었으나 마치 단일 시스템인 것처럼 수행되어야 함
    - 병렬 시스템
        - 문제 해결을 위해 CPU 등의 자원을 데이터 버스나 지역 통신 시스템 등으로 연결하여 구동하는 기술
        - 분할된 작업을 동시에 처리하여 계산 속도를 빠르게 함
    - 용어는 구분되어 사용되기도 하지만 서로 중첩되는 부분이 많아 실제 시스템에서도 이 둘을 명확히 구분하기 어려움
    - 두 개념을 아우르는 분산 병령 컴퓨팅이라는 용어를 사용
- 분산 병렬 컴퓨팅 : 다수의 독립된 컴퓨팅 자원을 네트워크상에 연결하여 이를 제어하는 미들웨어를 이용해 하나의 시스템으로 동작하게 하는 기술
- 분산 병렬 컴퓨팅 시 고려사항
    - 전체 작업의 배분 문제 : 전체 작업을 잘 쪼개어 여러 개의 작은 작업으로 나눠야 함|
    - 각 프로세서에서 계산된 중간 결과물을 프로세서 간 주고받는 문제
        - 효율적인 통신은 성능과 직결
        - 보통 단일 시스템은 전체 작업을 노드의 수만큼 균등하게 나눔
        - 이중 시스템은 컴퓨팅 능력에 따라 전체 작업을 배분
        - 노드 간의 통신을 최소화하는 기법 등이 반영되면 자원을 좀 더 효율적으로 사용할 수 있어 성능 향상에 도움
    - 서로 다른 프로세서 간 동기화 문제
        - 데이터 병렬 처리에서 동기적 방법을 사용할 경우 프로세서는 특정 계산이 끝나거나 특정 데이터를 넘겨받을 때까지 반드시 대기
        - 동기적 방법의 경우 송신자는 수신자에게서 데이터를 받았다는 응답이 올 때까지 대기
        - 비동기적 방법에서는 결과 메시지를 보낸 즉시 다음 작업을 계속할 수 있음
        - 비동기적 방법의 경우 프로세서는 기다릴 필요가 없지만, 계산 과정이 적합한지는 확인

- 하둡
    - 분선 처리 환경에서 대용량 데이터 처리 및 분석을 지원하는 오픈 소스 소프트웨어 프레임워크
    - 야후에서 최초로 개발, 지금은 아파치 소프트웨어 재단에서 프로젝트로 관리
    - 하둡 분산파일시스템인 HDFS와 분산칼럼기반 데이터베이스인 Hbase, 분산 컴퓨팅 지원 프레임워크인 맵리듀스로 구성
    - 분산파일시스템을 통해 수 천대의 장비에 대용량 파일을 나우어 저장할 수 있는 기능을 제공 : 분산파일시스템에 저장된 대용량의 데이터들을 맵리듀스를 이용하여 실시간으로 처리 및 분석 가능
    - 하둡의 부족한 기능을 보완하는 하둡 에코시스템이 등장하여 다양한 솔류선을 제공
- 아파치 스파크
    - 실시간 분산형 컴퓨팅 플랫폼으로 In-Memory 방식으로 처리를 하며 하둡보다는 처리속도가 빠름
    - 스칼라 언어로 개발되었지만 스칼라뿐만 아니라 Java, R, Python을 지원
- 맵리듀스
    - 구글에서 개발한 방대한 양의 데이터를 신속하게 처리하는 프로그래밍 모델로 효과적인 병렬 및 분산 처리 지원
    - 런타임에서의 입력 데이터 분할, 작업 스케줄링, 노드 고장, 노드 간의 데이터 전송 작업이 맵리듀스 처리 성능에 많은 영향을 미침

5) 빅데이터 분석

- 데이터 분석 방법의 분류
    - 탐구 용인 분석(EFA) : 데이터 간 상호 관계를 파악하여 데이터를 분석하는 방법
    - 확인 요인 분석(CFA) : 관찰된 변수들의 집합 요소 구조를 파악하기 위한 통계적 기법을 통해 데이터를 분석하는 방법
- 데이터 분석 방법
    - 분류 : 미리 알려진 클래스들로 구분되는 학습 데이터셋을 학습시켜 새로 추가되는 데이터가 속할 만한 데이터 셋을 찾는 지도학습 방법
    - 군집화 : 특성이 비슷한 데이터를 하나의 그룹으로 분류하는 방법으로, 분류와 달리 학습 데이터셋을 이용하지 않는 비지도학습 방법
    - 인공지능
        - 분야에서 인간의 학습을 모델링한 방법
        - 의사결정트리 등 기호적 학습과 신경망이나 유전 알고리즘 등 비기호적 학습, 베이지안이나 은닉 마코프 등 확률적 학습 등 다양한 기법
    - 텍스트 마이닝
        - 자연어 처리 기술을 이용해 인간의 언어로 쓰인 비정형 텍스트에서 유용한 정보를 추출하거나 다른 데이터와의 연견솽을 파악하기 위한 방법
        - 분류나 군집화 등 빅데이터에 숨겨진 의미 있는 정보를 발견하는 데 사용|
    - 웹 마이닝 : 인터넷을 통해 수집한 정보를 데이터 마이닝 방법으로 분석하는 응용분야
    - 오피니언 마이닝 : 온라인의 다양한 뉴스와 소셜 미디어 코멘트 또는 사용자가 만든 콘텐츠에서 표현된 의견을 추출, 분류, 이해하는 응용분야
    - 리얼리티 마이닝
        - 휴대폰 등 기기를 사용하여 인간관계와 행동 양태 등을 추론하는 응용분야
        - 통화량, 통화 위치, 통화 상태, 통화 대상, 통화 내용 등을 분석하여 사용자의 인간관계나 행동 특성을 찾아냄
    - 소셜 네트워크 분석 : 수학의 그래프 이론을 바탕으로 소셜 네트워크 서비스에서 네트워크 연결 구조와 강도를 분석하여 사용자의 명성 및 영향력을 측정하는 방법
    - 감성 분석
        - 문장의 의미를 파악하여 글의 내용에 긍정 또는 부정, 좋음 또는 나쁨을 분류하거나 만족 또는 불만족 강도를 지수화하는 방법
        - 도출된 지수를 이용하여 고객의 감성 트렌드를 시계열로 분석하고, 고객의 감성 변화에 기업들이 신속하게 대응 및 부정적인 의견의 확산을 방지하는 데 활용|

### 03. 빅데이터와 인공지능

1) 인공지능 (AI)

- 인공지능의 정의
    - 인공지능은 기계를 지능화하는 노력이며, 지능화란 객체가 환경에서 적절히, 그리고 예지력을 갖고 작동하도록 하는 것
    - 인고지능은 합리적 행동 수행자, 어떤 행동이 최적의 결과를 낳을 수 있도록 하는 의사결정 능력을 갖춘 에이전트를 구축하는 것
    - 인공지능은 설정한 목표를 극대화하는 행동을 제시하는 의사결정 로직
- 딥러닝의 특징
    - 딥러닝은 제프리 힌튼의 노력으로 함수추정 방법으로써의 신경망 관점에서 정보를 압축, 가공, 재현하는 알고리즘으로 일반화하면서 인공지능의 핵심 동인
    - 깊은 구조에 의해 엄청난 양의 데이터를 학습할 수 있는 특징 : 딥러닝의 학습을 위한 데이터의 확보는 곧 우수한 인공지능 개발과 깊은 관련성
- 기계 학습의 종류
    - 지도학습
        - 학습 데이터로부터 하나의 함수를 유추해내기 위한 방법
        - 지도 학습기가 하는 작업은 훈련 데이터로부터 주어진 데이터에 대해 예측하고자 하는 값을 올바로 추측해 내는 것
    - 비지도학습
        - 데이터가 어떻게 구성되었느지를 알아내는 문제의 범주에 속함
        - 지도학습 혹은 강화학습과는 달리 입력값에 대한 목표치가 주어지지 않음
        - 통계의 밀도 추정과 깊은 연관성, 데이터의 주요 특징을 요약하고 설명할 수 있음
    - 준지도학습
        - 목표값이 표시된 데이터와 표시되지 않은 데이터를 모두 학습에 사용하는 것
        - 많은 기계학습 연구자들이 목표값이 없는 데이터에 적은 양의 목표값을 포함한 데이터를 사용할 경우 학습 정확도에 있어서 상당히 좋아짐
    - 강화학습
        - 행동심리학에서 영감을 받았으며, 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 순서를 선택하는 방법
        - 강화학습의 초점은 학습 과정에서의 성능, 이는 탐색과 이용의 균형을 맞춤으로써 제고
- 기계학습 방법에 따른 인공지능 응용분야

|학습 종류|방법|응용 영역|
|---|---|---|
|지도학습|분류모형|이미지 인식, 음성 인식, 신용평가 및 사기검출, 불량예측 및 원인발굴|
|지도학습|회귀모형|시세/가격/주가 예측, 강우량 예측 등|
|비지도학습|군집분석|텍스트 토픽 분석, 고객 세그멘테이션|
|비지도학습|오토인코더|이상징후 탐지, 노이즈 제거, 텍스트 벡터화|
|비지도학습|생성적 적대 신경망|시뮬레이션 데이터 생성, 누락 데이터 생성, 패션 데이터 생성 등|
|강화학습|강화학습|게임 플레이어 생성, 로봇 학습 알고리즘, 공급망 최적화 등|

2) 인공지능 데이터 학습의 진화

- 전이학습
    - 인간의 응용력과 같이 유사 분야에 학습된 딥러닝 모형을 다른 문제를 해결하기 위해 사용하고자 할 때 적은 양의 데이터로도 좋은 결과를 얻을 수 있음
    - 주로 이미지, 언어, 텍스트 인식과 같이 지도학습 중 분류모형인 인식 문제에 활용 가능 : 인식 문제의 경우 데이터 표준화가 가능하여 사전학습모형 입력형식에 맞출 수 있음
- 전이학습 기반 사전학습모형 : 학습 데이터에 의한 인지능력을 갖춘 딥러닝 모형에 추가적인 데이터를 학습시키는 방식
    - 데이터 학습량에 따라 점차 발전하는 것도 중요하지만, 응용력을 갖추는 것도 필수적
    - 상대적으로 적은 양의 데이터로도 제한된 문제에 인공지능 적용이 가능 : 이미 학습된 사전학습모형도 데이터를 함축한 초보적 인공지능으로서 충분한 가치를 지닌 새로운 의미의 데이터
- BERT : 2018년 구글에서 발표한 언어인식 사전학습 모형
    - 학보된 언어 데이터의 추가 학습을 통한 신속한 학습 가능
    - 다층의 임베딩 구조를 통해 1억2천 개가 넘는 파라미터로 구성된 획기적인 모형
    - 256개까지의 문자가 입력되어 768차원 숫자 벡터가 생성되는 방식
    - 언어 인식뿐 아니라 번역, 챗봇의 Q&A 엔진으로 활용 가능

3) 빅데이터와 인공지능의 관계

- 인공지능을 위한 학습 데이터 확보
    - 학습 데이터 측면을 고려한 양질의 데이터 확보는 결국 성공적인 인공지능 구현과 직결
    - 딥러닝은 깊은 구조를 통해 무한한 모수 추정이 필요한 만큼 많은 양의 데이터 필요
    - 인공지능 학습에 활용될 수 있는 데이터로 가공이 필요, 학습의 가이드를 제공해 주는 애노테이션 작업이 필수적
- 학습 데이터의 애노테이션 작업
    - 많은 데이터 확보 후 애노테이션을 통해 학습이 가능한 데이터로 가공하는 작업 필요
    - 작업의 특성상 많은 수작업이 동반되며, 이로 인해 인공지능 사업은 노동집약적이라는 인식을 만들어 냄
- 애노테이션 작업을 위한 도구로써의 인공지능
    - 인공지능 시장이 확장되며 애노테이션 작업을 전문으로 하는 기업의 수 증가
        - 경쟁으로 인해 학습용 데이터에 대한 보안 및 애노테이션 결과에 대한 품질 요구수준이 높아짐
        - 기업들은 데이터 업로드 및 애노테이션 도구, 작업 모니터링을 위한 플랫폼을 제공 시작
    - 현재 자동으로 애노테이션을 수행해 주는 인공지능 기반의 애노테이션 도구를 제공하는 서비스로 진화 중

4) 인공지능의 기술동향

- 기계학습 프레임워크 보급 확대
    - 구글브레인이 개발한 텐서플로우는 파이썬 기반 딥러닝 라이브러리로 여러 CPU 및 GPU와 플랫폼에서 사용 가능
    - 케라스는 딥러닝 신경망 구축을 위한 단순화된 인터페이스를 가진 라이브러리이며, 몇 줄의 코드만으로 딥러닝 모형 개발이 가능
- 생성적 적대 신경망
    - GNA은 두 개의 인공신경망으로 구성된 딥러닝 이미지 생성 알고리즘
    - 생성자가 가짜 사례를 생성하면 감별자가 진위를 판별하도록 구성한 후 이들이 적대적 관계 속에서 공방전을 반복하도록 함 : 가짜 사례의 정밀도를 점점 더 진짜 사례와 구별하기 어려운 수준으로 높이는 방식으로 작동
    - 주로 새로운 합성 이미지를 생성하는 분석에 많이 적용되어 왔으나, 점차 다른 분야에 응용하는 사례가 늘고 있음
- 오토인코더
    - 라벨이 설정되어 있지 않은 학습 데이터로부터 더욱 효율적인 코드로 표현하도록 학습하는 신경망
    - 입력 데이터의 차원을 줄여 모형을 단순화시키기 위해 활용
- 설명 가능한 인공지능
    - 기존의 기계학습은 정확한 예측을 할 수 있도록 하는 방향으로 개발되어 짐
    - 기존 기계학습의 완성된 모형은 내부 구조가 매우 복자합하고 의미를 이해하기 어려워 일종의 블랙박스 모형
- 기계학습 자동화 : 기계학습의 전체 과정을 자동화
    - 데이터 전처리, 변수 생성, 변수 선택, 알고리즘 선택, 하이퍼파라미터 최적화 등의 기능을 수행
    - 기계학습 모형 개발 과정의 생산성을 높이며 비전문가들의 활용을 용이하게 할 것으로 기대

5) 인공지능의 한계점과 발전방향

- 국내시장의 한계
    - 국내에서 축적한 머신러닝 및 인공지능과 관련한 수학, 통계학적 이해도는 낮은 수준
    - 인공지능 개발을 위한 데이터 확보 및 그 중요성에 대한 인식이 부족함
- 인공지능의 미래
    - 딥러닝의 재학습 및 전이학습 특성을 활용한 사전학습모형이 새로운 데이터 경제의 모습이 됨
    - 마스킹이나 라벨링 등의 애노테이션 작업을 통해 학습용 데이터를 가공하는 산업 확산
    - 복잡한 BERT의 학습을 위한 구글의 클라우드 서비스와 같은 확장된 개념의 데이터 경제로 파생될 것으로 보임

### 04. 개인정보 개요

1) 개인정보의 정의와 판단기준

- 개인정보의 정의
    - 살아 있는 개인에 관한 정보로서 개인을 알아볼 수 있는 정보
    - 해당 정보만으로는 특정 개인을 알아볼 수 없더라도 다른 정보와 쉽게 결합하여 알아볼 수 있는 정보를 포함
- 개인정보의 판단기준
    - '생존하는' '개인에 관한' 정보
    - '정보'의 내용, 형태 등은 제한 없음
    - 개인을 '알아볼 수 있는' 정보여야 함 : 다른 정보와 '쉽게 결합하여' 개인을 알아볼 수 있는 정보도 포함

2) 개인정보의 처리와 활용
    
- 개인정보의 이전 : 개인정보가 다른 사람에게 이전되거나 공동으로 처리하게 하는 것
- 개인정보의 처리 위탁 : 개인정보처리자의 업무를 처리할 목적으로 제3자에게 이전되는 것
- 개인정보의 제3자 제공 : 해당 정보를 제공받는 자의 고유한 업무를 처리할 목적 및 이익을 위하여 개인정보가 이전되는 것

3) 개인정보의 보호

- 개인정보의 보호조치
    - 조직 내부의 정보보안 방침과 개인정보보호법에 위배되지 않도록 개인정보보호 가이드라인을 점검
    - 데이터를 외부에 공개하는 경우 가이드라인에서 정한 규칙을 준수하는지 반드시 확인
    - 가이드라인에 명시되지 않은 경우 관계기관이나 조직 내부의 법무가이드를 받은 후 적절한 범위 안에서 데이터를 활용
    - 개인정보 보호를 위해 주기적인 패스워드 변경, 시스템 패스워드 관리 보안 강화, 의심스러운 메일 열람 금지, 정기적인 보안교육 참여 등을 요구
    - 백신의 설치 및 최신버전으로 유지하고, 개인정보를 과하게 요구하는 사이트의 가업을 자제

### 05. 개인정보 법 · 제도

1) 개인정보보호법

- 개인정보보호법의 개요
    - 당사자의 동의 없는 개인정보 수집 및 활용하거나 제3자에게 제공하는 것을 금지하는 등 개인정보보호를 강화한 내용을 담아 제정한 법률
    - 상대방의 동의 없이 개인정보를 제3자에게 제공하면 5년 이하의 징역이나 5000만원 이하의 벌금에 처할 수 있음
- 개인정보의 범위(제2조 제1호)
    - 어떤 정보가 개인정보에 해당하는지는 그 정보가 특정 개인을 알아볼 수 있게하는 다른 정보와 쉽게 결합할 수 있는가에 따라 결정
    - 법원은 그 정보 자체로는 누구의 정보인지를 알 수 없더라도 다른 정보와 결합 가능성을 비교적 넓게 인정하여 개인정보에 해당한다 판단
- 개인정보의 처리 위탁
    - 일정한 내용을 기재한 문서에 의하여 업무 위탁이 이루어져야 함
    - 위탁하는 업무의 내용과 수탁자를 정보주체엑 알려야 하는바, 개인정보처리방침에 해당 내용을 추가하여 공개하거나, 사업장 등의 보기 쉬운 장소에 게시하는 방법 등을 시행
    - 수탁자에 대한 교육 및 감독 의무를 부담
    - 수탁자가 위탁 받은 업무와 관련하여 개인정보를 처리하는 과정에서 개인정보보호법을 위반하여 발생한 손해배생책임에 대하여는 수탁자를 개인정보처리자의 소속 직원으로 봄
    - 손해가 발생한 경우 정보주체의 손해배상 청구에 대해 위탁자가 책임
- 개인정보의 제3자 제공 : 정보주체로부터 개인정보 제3자 제공 동의를 받아야 함

2) 정보통신망 이용촉진 및 정보보호 등에 관한 법률(정보통신망법)

- 정보통신망법의 개요
    - 정보통신망의 개발과 보급 등 이용 촉진과 함께 통신망을 통해 활용되고 있는 정보보호에 관해 규정한 법률
    - 이용자의 동의를 받지 ㅇ낳고 개인정보를 수집하거나 제3자에게 개인정보를 제공한 경우, 법정대리인의 동의 없이 만 14세 미만의 아동의 개인정보를 수집한 경우, 악성프로그램을 전달 또는 유포한 경우 등은 5년 이하의 징역 또는 5000만 원 이하의 벌금
- 개인정보의 처리 위탁
    - 원칙적으로는 개인정보 처리위탁을 받는 자, 개인정보 처리위탁을 하는 업무의 내용을 이용자에게 알리고 동의 받아야 함
    - 단, 정보통신서비스 제공자 등은 정보통신서비스의 제공에 관한 계약을 이행하고 이용자의 편의 증진 등을 위하여 필요한 경우에는 고지절차와 동의절차를 거치지 ㅇ낳고, 이용자에게 이에 관해 알리거나 개인정보 처리방침 등에 이를 공개할 수 있음
    - 만일 제3자에게 데이터 분석을 위탁할 경우, 해당 서비스가 정보통신서비스 제공에 관한 계약을 이행하고 이용자의 편의 증진을 위한 것인지 검토해야 함

3) 신용정보의 이용 및 보호에 관한 법률(신용정보보호법)

- 신용정보보호법의 개요
    - 개인신용정보를 신용정보회사 등에게 제공하고자 하는 경우에 해당 개인으로부터 서면 똔느 공인전자서명이 있는 전자문서에 의한 동의 등을 얻어야 함
    - 신용정보주체는 신용정보회사 등이 본인에 관한 신용정보를 제공하는 때에는 제공받은 자, 그 이용 목적, 제공한 본인정보의 주요 내용 등을 통보하도록 요구하거나 인터넷을 통하여 조회할 수 있도록 요구 가능
    - 신용정보회사 등이 보유하고 있는 본인정보의 제공 또는 열람을 청구할 수 있고, 사실과 다른 경우에는 정정을 청구 가능
- 개인정보의 범위(제2조 제1호 및 제2호, 제 34조 제1항)
    - '신용정보' : 금융거래 등 상거래에 있어서 거래 상대방의 신용을 판단할 때 필요한 정보로서 다음 각 목의 정보를 말함
        - 특정 신용정보주체를 식별할 수 있는 정보
        - 신용정보주체의 거래내용을 판단할 수 있는 정보
        - 신용정보주체의 신용도를 판단할 수 있는 정보
        - 신용정보주체의 신용거래능력을 판단할 수 있는 정보
        - 그 밖에 위처럼 유사한 정보
- 개인신용정보 : 금융거래 등 상거래에 있어서 거래 상대방에 대한 신용도·신용거래능력 등의 판단을 위해 필요로 하는 정보로 정의하고, 그 세부 사항은 대통령령으로 정함
- 개인신용정보의 처리 위탁
    - 신용정보회사 등은 그 업무 범위에서 의뢰인의 동의를 받아 다른 신용정보회사에 신용정보의 수집·조사를 위탁 가능
    - 신용정보회사, 신용정보집중기간, 은행, 금융지주회사, 금융투자업자, 보험회사 등은 신용정보 처리 위탁 시 금융위원회에 보고해야 하며, 이에 관한 구체적 사항은 '금융회사의 정보처리 업무 위탁에 과한 규정'에 따름
    - 특정 신용정보주체를 식별할 수 있는 정보는 암호화하거나 봉함 등의 보호조치를 하여야 하며, 신용정보가 분실·도난·유출·변조 또는 웨손당하지 않도록 수탁자를 연 1회 이상 교육해야 함
    - 위탁계약의 이행에 필요한 경우로서 수집된 신용정보의 처리를 위탁하기 위하여 제공하는 경우 정보주체의 동의를 받지 않아도 됨
- 개인신용정보의 제3자 제공
    - 개인신용정보를 타인에게 제공하려는 경우 정보주체에 서비스 제공을 위하여 필수적 동의 사항과 그 밖의 선택적 동의 사항을 구분하여 설명한 후 각각 동의를 받도록 함
    - 기타 개인정보 제공 시 개인정보보호법이 적용

4) 2020년 데이터 3법의 주요 개정 내용

- 개인정보보호법 주요 개정 내용
    - 개인정보 관련 개념을 개인정보, 가명정보, 익명정보로 구분
    - 가명정보를 통계 작성 연구, 공익적 기록보존 목적을 처리할 수 있도록 허용
    - 가명정보 이용 시 안전장치 및 통제 수단 마련
    - 분산된 개인정보보호 감독기관을 개인정보보호위원회로 일원화
    - 개인정보보호위원회는 국무총리 소속 중앙행정기관으로 격상
- 정보통신망법 주요 개정 내용
    - 개인정보보호 관련 사항을 개인정보보호법으로 이관
    - 온라인상 개인정보보호 관련 규제 및 감독 주체를 개인정보보호위원회로 변경
- 신용정보보호법 주요 개정 내용
    - 가명정보 내용을 도입해 빅데이터 분석 및 이용의 법적 근거 마련
    - 가명정보는 통계작성, 연구, 공익적 기록보존 등을 위해 신용정보 주체의 동의 없이 이용, 제공 가능

### 06. 개인정보 비식별화

1) 개인정보 비식별화의 개요

- 비식별 정보 : 정보의 집합물에 대해 '개인정보 비식별 조치 가이드라인'에 따라 적정하게 '비식별 조치'된 정보를 말함
- 비식별 조치 : 정보의 집합물에서 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제하거나 대체 등의 방법을 통해 개인을 알아볼 수 없도록 하는 조치
- 비식별 정보의 활용
    - 비식별 정보는 개인정보가 아닌 정보로 추정되므로 정보주체로부터의 별도 동의없이 해당 정보를 이용하거나 제3자에게 제공할 수 있음
    - 다만, 불특정 다수에게 공개되는 경우에는 다른 정보를 보유하고 있는 누군가에 의해 해당 정보주체가 식별될 가능성이 있으므로 비식별 정보의 공개는 원칙적으로 금지
- 비식별 정보의 보호
    - 비식별 정보는 개인정보가 아닌 것으로 추정되지만, 새로운 결합 기술이 나타나거나 결합 가능한 정보가 증가하는 경우에는 정보주체가 '재식별'될 가능성이 있음
    - 비식별 정보를 처리하는 자(비식별 정보를 제공받은 자 포함)가 해당 정보를 이용하는 과정에서 재식별하게 된 경우에는 해당 정보를 즉시 처리중지하고 파기하여야 함
    - 비식별 정보라고 하더라도 필수적인 관리적·기술적 보호조치는 이행해야 함

2) 개인정보 비식별화 조치 가이드라인

- 개인정보 비식별화 조치 가이드라인의 추진배경
    - 정부 3.0 및 빅데이터 활용 확산에 따른 데이터 활용가치가 증대
    - 개인정보 보호 강화에 대한 사회적 요구가 지속
    - '보호와 활용'을 동시에 모색하는 세계적 정책변화에 적극 대응 필요
- 개인정보 비식별화 조치 가이드라인의 단계별 조치사항

|단계|조치사항|데이터|
|----|---|---|
|사전 검토|개인정보에 해당하는지 여부를 검토한 후, 개인정보가 아닌 것이 명백한 경우 법적 규제 없이 자유롭게 활용|개인정보, 식별정보|
|비식별 조치|정보 집합물(데이터 셋)에서 개인을 식별할 수 있는 요소를 전부 또는 일부 삭제하거나 대체하는 등의 방법을 활용, 개인을 알아볼 수 없도록 하는 조치|가명, 총계, 삭제, 범주화, 마스킹|
|적정성 평가|다른 정보와 쉽게 결합하여 개인을 식별할 수 있는지를 '비식별 조치 적정성 평간단'을 통해 평가|k-익명성, i-다양성, i-근접성|
|사후 관리|비식별 정보 안전조치, 재식별 가능성 모니터링 등 비식별 정보 활용 과정에서 재식별 방지를 위해 필요한 조치 수행|관리적/기술적 보호조치

- 개인정보 비식별화 조치 가이드라인의 조치방법
    - 가명 처리
        - 개인정보 중 주요 식별 요소를 달느 값으로 대체하는 방법
        - 값을 대체 시 규칙이 노출되어 역으로 쉽게 식별할 수 없도록 주의
    - 총계 처리
        - 데이터의 초합 값을 보여 주고 개별 값을 보여 주지 않는 방법
        - 특정 속성을 지닌 개인으로 구성된 단체의 속성 정보를 공개하는 것을 그 집단에 속한 개인의 정보를 공개하는 것이므로 주의
    - 데이터 사게 : 데이터 공유나 개방 목적에 딸는 데이터 셋에 구성된 값 중 필요 없는 값 또는 개인식별에 중요한 값을 삭제하는 방법
    - 데이터 범주화 : 데이터의 값을 범주의 값으로 변환하여 값을 숨기는 방법
    - 데이터 마스킹
        - 개인을 식별하는 데 기여할 화귤ㄹ이 높은 주요 식별자를 보이지 않도록 처리하는 방법
        - 남아 있는 정보만으로 개인을 식별할 수 없어야 하며, 공개된 다른 정보와 결합하더라도 특정 개인을 식별할 수 없어야 함

### 07. 개인정보 활용

1) 데이터 수집의 위기 요인과 통제 방안

- 사생활 침해의 위기 발생
    - M2M 시대가 되면서 정보를 수집하는 센서들의 수가 증가
    - 개인정보의 가치가 커짐에 따라 많은 사업자들이 개인정보 습득에 더 많은 자원 투입
    - 특정 데이터가 본래 목적 외로 가공되어 2차, 3차 목적으로 활용될 가능성이 커짐
    - 위험의 범위가 사생활 침해 수준을 넘어 사회, 경제적 위험으로 더 확대될 수 있음
- 동의에서 책임으로 강화하여 통제
    - 개인정보는 본래의 1차적 목적 외에도 2차, 3차적 목적으로 가공, 유통, 활용 : 개인정보의 활용에 대해 개인이 매번 동의하는 것은 매우 어려운 일, 경제적으로도 비효율적
    - 개인정보 사용으로 발생하는 피해에 대해서는 개인정보 사용자가 책임을 지게 함
    - 개인정보를 사용하는 주체가 익명화 기술 같은 더 적극적인 보호 장치를 마련하게 하는 효과가 있을 것으로 기대

2) 데이터 활용의 위기 요인과 통제 방안

- 책임원칙 훼손으로 위기 발생
    - 빅데이터의 분석 결과에 따라 특정한 행위를 할 가능성이 높다는 이유만으로 특정인이 처벌받는 것은 민주주의 사회 원칙 훼손
    - 특정인이 특정한 사회, 경제적 특성을 가진 집단에 속한다는 이유만으로 그의 신용도와 무관하게 대출이 거절되는 상황은 잘못된 클러스터링의 피해
- 결과 기반 책임 원칙을 고수하여 통제
    - 기존의 책임 원칙을 더 강화
    - 예측 결과에 의해 불이익을 당할 가능성을 최소화하는 방안 마련 필요
    - 제도 마련과 함께 알고리즘의 기술적 완성도를 더 높여야 함

3) 데이터 처리의 위기 요인과 통제 방안

- 데이터 오용으로 위기 발생
    - 빅데이터는 과거에 일어났던 일로 인해 기록된 데이터에 의존 : 빅데이터를 기반으로 미래를 예측하는 것은 어느 정도 정확도를 가질 수 있지만 항상 맞는 것은 아님
    - 빅데이터 사용자가 데이터를 과신할 때 큰 문제가 발생할 가능성이 높음 : 잘못된 지표를 사용하는 것은 오히려 과거 경험에 의존하는 것보다 더 잘못된 결론을 도출할 수 있음
- 알고리즘 접근을 허용하여 통제
    - 알고리즘에 대한 접근권한을 부여받아 직접 검증할 수 있도록 함
    - 알고리즘에 대한 객과적인 인증방안을 마련 및 도입
    - 알고리즘의 부당함을 반증할 수 있는 방법을 제시해 줄 것을 요청
    - 공개해 준 알고리즘을 해석해 줄 알고리즈미스트와 같은 전문가 영입 : 알고리즈미스트는 컴퓨터, 수학, 통계학, 비즈니스 등의 다양한 지식 필요