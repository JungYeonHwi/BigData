# 분석모형 평가 및 개선

## SECTION 01. 분석모형 평가

### 01. 평가 지표

1) 지도학습-분류모델 평가 기준

![image](./%EC%98%A4%EC%B0%A8%ED%96%89%EB%A0%AC.png)

- 오차행렬 : 훈련을 통한 예측 성능을 측정하기 위해 예측 값과 실제 값을 비교하기 위한 표
- 정확도 : 실제 데이터와 예측 데이터를 비교하여 같은 지 판단
- 정밀도 : Positive로 예측한 대상 중에 실제와 예측 값이 일치하는 비율
- 재현율 : 실제 Positive인 대상 중에 실제와 예측 값이 일치하는 비율
- F1 Score : 정밀도와 재현율을 결합한 조화평균 지표로 값이 클수록 모형이 정확하다고 판단
- ROC 곡선 : FPR이 변할 때 민감도인 TPR이 어떻게 변화하는지를 나타내는 곡선
    - 임계값이 1이면 확률이 1일때 True로 예측하므로 FP가 0으로 FPR이 0이 됨
    - 임계값을 1~0 범주 이내 값으로 조정하면서 FPR에 따른 TPR을 계산하면서 곡선을 그림
    - TPR 값과 FPR 값이 0.5인 기본 모델 위에 ROC가 위치할 경우 성능이 기본 모델보다 나음
- AUC : 평가모델의 ROC 곡선의 하단 면적을 뜻하며 랜덤일 때 0.5 값으로 ROC 곡선이 직선에서 멀어질수록 성능이 더 뛰어남

2) 지도학습-회귀모델 평가 기준

- 회귀의 평가를 위한 지표는 실제값과 회귀 예측값의 차이를 기반으로 성능지표들을 수립, 활용
- SSE : 실제값과 예측값의 차이를 제곱하여 더한 값
- MSE : 실제값과 예측값의 차이의 제곱에 대한 평균을 취한 값으로 평균제곱 오차라고도 함
- RMSE : MSE에 루트를 취한 값으로 평균제곱근 오차라고도 함
- MAE : 실제값과 예측값의 차이의 절대값을 합한 평균값
- 결정계수 R^2 : 회귀모형이 실제값에 대해 얼마나 잘 적합하는 지에 대한 비율
- Adjusted R^2 : 다변량 회귀분석에서 독립변수가 많아질수록 결정계수가 높아지는데 이를 보완한 결정계수로 표본크기(n)와 독립변수의 개수(p)를 추가적으로 고려하여 분모에 위치시킴으로써 결정계수 값이 증가도를 보정
- MSPE : MSE를 퍼셉트로 변환한 값
- MAPE : MAE를 퍼셉트로 변환한 값
- RMSLE : RMSE에 로그를 취한 값으로 이상치에 덜 민감
- AIC : 최대 우도에 독립변수의 개수에 대한 손실분을 반영하는 목적으로 모형과 데이터의 확률 분포 차이를 측정하는 것으로 AIC값이 낮을수록 모형의 적함도 높아짐
- BIC : AIC와 동일한 목적을 지니나 주어진 데이터에서 모형의 우도를 측정하기 위한 값에서 유도한 지표로 변수 개수가 많을수록 AIC보다 더 패널티를 가하는 성격

3) 비지도학습-군집분석 평가 지표

- 비지도학습은 지도학습과 달리 실측자료에 라벨링이 없으므로 모델에 대한 성능평가가 어려움
- 군집분석에 한해 다음과 같은 성능 평가 지표 참고
- 실루엣 계수
- Dunn Index 

### 02. 분석모형 진단

1) 정규성 가정

- 정규성 가정은 통계적 검정, 회귀분석 등 분석을 진행하기 전에 데이터가 정규분포를 따르는지를 검정하는 것으로 데이터 자체의 정규성을 확인하는 과정
- 중심극한정리 : 동일한 확률분포를 가진 독립 확률 변수 n개의 평균의 분포는 n이 적당히 크다면 정규분포에 가까워진다는 이론으로 이때 표본분포의 평균은 모집단의 모평균과 동일하며 표준편차는 모집단의 모표준편차를 표본 크기의 제곱근으로 나눈 것과 동일
- 정규성 검정 종류
    - 샤피로-월크 검정 : 표본수(n)개가 2000개 미만인 데이터 셋에 적합
    - 콜모고로프 스미르노프 검정 : 표본수(n)개가 2000개 초과인 데이터 셋에 적합
    - Q-Q 플롯 : 데이터 셋이 정규분포를 따르는지 판단하는 시각적 분석 방법으로 표본수(n)가 소규모일 경우 적합
- 데이터 셋이 정규분포를 따른다는 귀무가설을 기각하고 대립가설이 채택된다면 해당 데이터 셋은 정규분포를 따르지 않으므로 증명

2) 잔차 진단

- 회귀분석에서 독립변수와 종속변수의 관계를 결정하는 회귀선은 실측치와 예측치의 차이인 잔차를 가장 작게 해주는 선으로 잔차의 합은 0이며 잔차는 추세, 특정 패턴을 가지고 있지 않음
- 잔차의 정규성 판단 : 신뢰구간 추정과 가설검증을 정확하게 하기 위해 Q-Q Plot과 같은 시각화 도표를 통해 정규분포와 잔차의 분포 비교
- 잔차의 등분산성 진단 : 잔차의 분산이 특정 패턴이 없이 순서와 무관하게 일정한지 등분산성을 진단
- 잔차의 독립성 진단 : 자기상관의 여부를 판단하는 것이며 시점 순서대로 그래프를 그리거나 더빈-왓슨 검정으로 패턴이 없다면 독립성을 충족한다고 할 수 있음

### 03. K-폴드 교차검증

1) K-폴드 교차검증

- 고정된 훈련데이터 셋과 테스트검증데이터 셋으로 평가를 하여 반복적으로 튜닝하게 될 시 테스트데이서 셋에 과적합 되어버리는 결과가 생길 수 있는데 이를 방지하고자 나온 방법이 교차검증 기법
- K-폴드 교차검증 기법은 전체 데이터 셋을 k개의 서브셋으로 분리하여 그 중에 k-1개를 훈련데이터로 사용하고 1개의 서브셋은 테스트데이터로 사용, 테스트 셋을 중복없이 병행 진행한 후 평균을 내어 최종적 모델의 성능 평가
- 교차검증은 모든 데이터 셋을 평가에 활용하여 과적합을 방지할 수 있으나 반복횟수 증가에 따른 모델 훈련과 평가/검증 시간이 오래 걸릴 수 있음
- 교차검증 기법들로 k-폴드 교차검증 외 홀드아웃 기법, 리브-p-아웃 교차검증, 리브-원-아웃 교차검증, 계층별 k-겹 교차검증 등
- 홀드아웃 기법 : 일반적으로 훈련데이터 셋과 테스트검증데이터 셋으로 구분한 뒤 훈련데이터로 모델을 학습하고 테스트데이터로 성능을 증가시키는 방법으로 사용하는데, 동일한 테스트데이터를 계속 사용한다면 모델이 테스트데이터에 과적합하게 됨

### 04. 적합도 검정

1) 적합도 검정 : 일반적인 적합도 검정 방법으로 정규성 검정이 있으며 모집단의 분포를 정규분포로 가정하는 분석기법이 적용될 시 데이터가 정규분포를 따르는가를 확인할 때 사용

2) 카이제곱 검정 : 기대값과 관측값을 이용한 방법으로 k개의 범주별로 나뉘어진 관측치들과 이와 동일한 범주의 가정된 분포 사이의 적합도를 검정하며 범주형 값  k가 나와야 할 횟수의 기댓값 mk와 실제 나온 횟수 xk의 차이를 이용하여 검정통계량을 구함

3) 콜모고로프 스미르노프 검정

- 관측된 표본분포와 가정된 분포사이의 적합도를 검사하는 누적분포함수의 차이를 이용한 검정법으로 연속형 데이터에도 적용 가능
- 관측된 자료의 크기를 나열, 관측치들의 누적확률을 구하여 가정된 분포의 누적확률과 비교하는 순서로 진행됨

## SECTION 02. 분석모형 개선

### 01. 과대적합 방지

1) 모델의 낮은 복잡도

- 훈련데이터를 더 많이 획득할 수 없다면 정규화, 드롭아웃 등을 활용하여 적절한 복잡도를 가진 모델을 자동으로 탐색
- 학습을 하면서 지속적으로 바귀는 가중치 매개변수가 아닌 상수값인 하이퍼파라미터는 과대적합의 위험을 줄이기 위해 제약을 가하는 규제의 양을 결정하는 인수로 큰 값을 지정할수록 복잡도가 낮은 모델을 얻게 됨
- 드롭아웃
    - 신경망 모델에서 은닉층의 뉴런을 임의로 삭제하면서 학습하는 방법으로 훈련 시에는 삭제할 뉴런을 선택하며 테스트 시에는 모든 뉴런에 신호를 전달, 각 뉴런의 출력에 훈련 때 삭제한 비율을 곱하여 전달
    - 적은 수의 뉴런들로 학습을 진핼할 때 시간이 오래 걸리는 단점

2) 가중치 감소

- 학습과정에서 큰 가중치에 대해서는 큰 패널티를 부과하여 가중치의 절대값을 가능한 작게 만듦, 규제란 과대적합이 되지 않도록 모델을 강제로 제한하는 의미로 L1, L2 규제가 있음
- L2 규제
    - 손실함수에 가중치에 대한 L2 노름의 제곱을 더한 패널티를 부여하여 가중치 값을 비용함수 모델에 비해 작게 만들어 냄
    - 손실함수가 최소가 되는 가중치 값인 중심 점을 찾아 큰 가중치를 제한하는데 람다로 규제의 강도를 크게 하면 가중치는 0에 가까워짐
    - 회귀 모델에서 L2 규제를 적용한 것이 릿지 모델
- L1 규제
    - L1 규제는 L2 규제의 가중치 제곱을 절대값으로 바꾸는 개념으로 손실 함수에 가중치의 절대값인 L1 노름을 추가 적용하여, 희소한 특성 벡터가 되어 대부분의 특성 가중치를 0으로 만듦
    - 회귀 모델에서 L1 규제를 적용한 것이 라쏘 모델

3) 편향-분산 트레이드 오프 : 과대적합과 과소적합 사이의 적절한 편향-분산 트레이드오프, 절충점을 찾음

### 02. 매개변수 최적화

1) 매개변수 최적화 : 신경망 학습의 목표는 손실 함수의 값을 최대한 낮추는 매개변수를 찾는 것으로 이러한 매개변수의 최적값을 찾는 과정

2) 확률적 경사 하강법(SGD)

- 최적의 매개변수 값을 찾기 위해 매개변수에 대한 손실한 수의 기울기 이용, 손실함수의 기울기를 따라 조금씩 아래로 내려가다 최종적으로 손실함수가 가장 작은 지점에 도달하도록 하는 알고리즘
- 데이터 전체를 선택하는 배치 경사 하강법과 비교하면, 랜덤으로 선택한 하나의 데이터로만 계산하는 단순하고 명확한 구조가 장점
- 해당 알고리즘 수식은 갱신할 가중치 매개변수인 W, dL/dw, 매개변수에 대한 손실함수의 기울기와 학습률로 설명

3) 모멘텀

4) AdaGrad

5) Adam

6) 초매개변수 : 사람이 직접 설정해주어야 하는 매개변수로 뉴런의 수, 배치 크기, 학습률, 은닉층 개수

- 학습율 : 기울기 방향으로 얼마나 빠르게 이동할지를 결정, 학습률이 작으면 학습 시간이 길어지고 학습률이 커지면 발산하여 학습이 제대로 이루어지지 않을 수 있음
- 미니배치 크기
    - 전체 훈련데이터 셋을 신경망에 넣게 되면 리소스가 비효율적으로 사용되고 시간이 오래 걸리므로 배치 개념을 사용하게 됨
    - 미니배치는 전체 학습 데이터를 주어진 배치 크기로 나눈 것으로 미니배치 크기가 큰 경우 병렬연산 구조를 사용할 때 효과적일 수 있으며, 크기가 작으면 더 많은 가중치 업데이틀 할 수 있음
- 훈련 반복 횟수 : 전체 훈련데이터 셋이 신경망을 통과한 횟수로, 1 Epoch는 1회 학습으로 통과했다는 뜻이며 학습의 조기 종료를 결정하는 변수가 됨
- 이터레이션
    - 하나의 미니배치를 학습할 때 1 Iteration으로 1회 매개 변수(파라미터) 업데이트 진행됨
    - 미니배치 개수와 이터레이션 개수는 동일
- 은닉층 개수
    - 은닉층 수가 많아질수록 특정 훈련데이터에 더 최적화시킬 수 있음
    - 모든 은닉층들의 뉴런의 개수를 동일하게 유지하는 것이 같은 은닉층 개수에 뉴런의 개수를 가변적으로 하는 것보다 효과적
    - 첫 번재 은닉층에 있는 뉴런의 개수가 입력층에 있는 뉴런의 개수보다 큰 것이 효과적인 경우가 많음

### 03. 분석모형 융합

1) 분석모형 융합 : 분석 성능을 향상하기 위해 구축된 여러 모형을 결합, 융합

2) 앙상블 학습

- 주어진 자료를 이용하여 여러 가지 분석 예측모형들을 만들고 해당 예측모형들을 결합하여 최종적인 하나의 예측모형을 만드는 방법
- 장점
    - 치우침이 있는 여러 모형의 평균을 취합 시 균형적인 결과(평균)를 얻음
    - 여러 모형의 분석 결과를 결합하면 변동성 및 과적합의 여지가 줄어듦
- 종류 : 배깅, 부스팅, 랜덤 포레스트 등

3) 결합분석모형 : 두 종류 이상의 결과변수를 동시에 분석할 수 있는 방법으로 결과 변수 간의 유의성, 관련성 설명 가능

### 04. 최종모형 선정

1) 회귀모형에 대한 주요 성능평가지표

- SSE : 실제값과 예측값의 차이를 제곱하여 더한 값
- 결정계수 R ^ 2 : 적합한 회귀모형이 실제값을 얼마나 잘 적합하는 지에 대한 비율
- MAE : 실제값과 예측값의 차이의 절대값을 합한 평균값
- MAPE : MAE 계산 시 실제값에 대한 상대적인 비율 고려

2) 분류모형에 대한 주요 성능평가지표

3) 비지도학습 모형에 대한 주요 성능평가지요

- 군집분석 : 군집타당성지표로 군집 간 분산과 군집 내 분산으로 군집 간 거리, 군집의 지름, 군집의 분산 등을 고려
- 연관분석 : 연관분석은 연관규칙에서 지지도와 신뢰도가 모두 최소한도보다 높은 것으로 평가하며 일반적으로 최소 지지도를 정한 뒤에 이에 대한 이하를 버리르 그 중에 신뢰도가 어느정도 높은 결과들을 가져옴