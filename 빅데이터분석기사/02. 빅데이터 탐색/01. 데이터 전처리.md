# 데이터 전처리

## SECTION 01. 데이터 정제

### 01. 데이터에 내재된 변수의 이해

1) 데이터 관련 정의

- 데이터 : 이론을 세우는 기초가 되는 사실 또는 자료를 지칭하며 컴퓨터와 연관되어 프로그램을 운용할 수 있는 형태로 기호화, 수치화한 자료
- 단위 : 관찰되는 항목 또는 대상
- 관측값 : 각 조사 단위별 기록정보 또는 특성
- 변수 : 각 단위에서 측정된 특성 결과
- 원자료 : 표본에서 조사된 최초의 자료

2) 데이터의 종류

- 단변량자료 : 자료의 특성을 대표하는 특성 변수가 하나인 자료
- 다변량자료 : 자료의 특성을 대표하는 특성 변수가 두 가지 이상인 자료
- 질적자료 : 정성적 또는 범주형 자료라고도 하며 자료를 범주의 형태로 분류, 분류의 편의상 부여된 수치의 크기자체에는 의미를 부여하지 않느 자료이며 명목자료, 서열자료 등 이질적자료로 분류
    - 명목자료 : 측정대상이 범주나 종류에 대해 구분되어지는 것을 수치 또는 기히로 분류되는 자료
    - 서열자료 : 명목자료와 비슷하나 수치나 기호가 서열을 나타내는 자료
- 수치자료 : 정량적 또는 연속형 자료, 숫자의 크기에 의미를 부여할 수 잇는 자료로 나타내며 구간자료, 비율자료가 여기에 속함
    - 구간자료 : 명목자료, 서열자료의 의미로 포함되면서 숫자로 표현된 변수에 대해서 변수 간의 관계가 산술적인 의미를 가지는 자료
    - 비율자료 : 명목자료, 서열자료, 구간자료의 의미를 다 가지는 자료로서 수치화된 변수에 비율의 개념을 도입할 수 있는 자료
- 시계열자료 : 일정한 시간간격 동안에 수집된, 시간개념이 포함되어 있는 자료
- 횡적자료 : 횡단면자료라고도 하며 특정 단일시점에서 여러 대상으로부터 수집된 자료, 한 개의 시점에서 여러 대상으로부터 취합하는 자료
- 종적자료 : 시계열자료와 횡적자료의 결합으로 여러 개체를 여러 시점에서 수집한 자료

3) 데이터의 정제 : 수집된 데이터를 대상으로 분석에 필요한 데이터를 추출하고 통합하는 과정

- 데이터 정제의 필요성 : 데이터로부터 원하는 결과나 분석을 얻기 위해서는 수집된 데이터를 분석의 도구 도는 기법에 맞게 다듬는 과정 필요
- 정제과정을 거치지 않은 데이터의 문제점
    - 데이터 구성의 일관성이 없어지므로 분석의 처리에 어려움 발생
    - 도출된 결과의 신뢰성 저하 발생
- 데이터 정제의 과정
    - 다양한 매체로부터 데이터를 수집, 원하는 형태로 변환, 원하는 장소에 저장, 저장된 데이터의 활용가능성을 타진하기 위한 품질확인, 필요한 시기에 목적에 따라 사용이 원활하도록 관리의 과정 필요
    - 시스템 내, 외부에서 데이터를 수집하면 정형보다는 비정형 데이터들이 많음, 비정형 데이터의 경우 기본적으로 구조화된 정형 데이터로의 변환을 수행하고 변환된 데이터에서 결측치나 오류의 수정 과정을 거침
- 기존 시스템 내의 데이터와 비교분석이 필요한 경우, 레거시와 통합, 변환의 과정이 발생
- 데이터 정제의 전처리, 후처리
    - 전처리 : 데이터 저장 전의 처리과정으로 대상 데이터의 입수방법 결정 및 저장방식 장소 선정
    - 후처리 : 저장 후의 처리를 지칭하며 저장 데이터의 품질관리 등의 과정 포함

### 02. 데이터 결측값 처리

1) 결측치 데이터

- 결측치를 임의로 제거 시 : 분석 데이터의 직접손실로 분석에 필요한 유의수준 데이터 수집에 실패할 가능성 발생
- 결측치를 임의로 대체 시 : 데이터의 편향이 발생하여 분석 결과의 신뢰성 저하 가능성

2) 결측 데이터의 종류

- 완전 무작위 결측 : 어떤 변수상에서 결측 데이터가 관측된 혹은 관측되지 않는 다른 변수와 아무런 연관이 없는 경우
- 무작위 결측 : 변수상의 결측데이터가 관측된 다른 변수와 연관되어 있지만 그 자체가 비관측값들과는 연관되지 않은 경우
- 비 무작위 결측 : 어떤 변수의 결측 데이터가 완전 무작위 결측 또는 무작위 결측이 아닌 결측데이터로 정의하는 즉, 결측변수값이 결측여부(이유)와 관련이 있는 경우

3) 결측값 유형의 분석 및 대치

- 결측치의 처리를 위해서 실제 데이터셋에서 어떤 유형으로 분류되는지 분석하고 분석된 결과에 따라서 결측치 처리 방법의 선택 필요
- 일반적으로 결측, 무응답을 가진 자료를 분석할 때는 완전 무작위 결측하에 처리, 즉 불완전한 자료는 무시하고 완전히 관측된 자료만을 표준적 분석 시행, 그러나 이런 결측치가 존재하는 데이터를 이용한 분석은 다음 세 가지 고려사항이 발생하는데 효율성문제, 자료처리의 복잡성, 편향 문제
    - 단순 대치법 : 기본적으로 결측치에 대하여 MCAR 또는 MAR로 판단하고 이에 대한 처리를 하는 방법
        - 완전 분석 : 불완전 자료는 완전하게 무시하고 분석을 수행, 분석의 용이성을 보장하나 효율성 상실과 통계적 추론의 타당성에 문제 발생 가능성
        - 평균 대치법 : 관측 또는 실험으로 얻어진 데이터의 평균으로 결측치를 대치에서 사용, 평균에 의한 대치는 효율성의 향상 측면에서 장점이 있으나 통계량의 표준오차가 과소 추정되는 다점, 비조건부 평균 대치법
        - 회귀 대치법 : 회귀분석에 의한 예측치로 결측치를 대치하는 방법으로 조건부 평균 대치법
        - 단순확률 대치법 : 평균 대치법에서 추정량 표준오차의 과소 추정을 보완하는 대치법으로 Hot-deck 방법이라고도 함, 화귤ㄹ 추출에 의해서 전체 데이터 중 무작위로 대치하는 방법
        - 최근접 대치법 : 전체표본을 몇 개의 대체군으로 분류하여 각 층에서의 응답자료를 순서대로 정리한 후 결측값 바로 이전의 응답을 결측치로 대치, 응답값이 여러 번 사용될 가능성이 단점
    - 다중 대치법 : 단순 대치법을 복수로 시행하여 통계적 효율성 및 일치성 문제를 보완하기 위하여 만들어진 방법, 복수 개(n개)의 단수대치를 통해 n개의 새로운 자료를 만들어 분석을 시행하고 시행결과 얻어진 통계랑에 대해 통계량 및 분산 결합을 통해 통합하는 방법
        - 1단계-대치단계 : 복수의 대치에 의한 결측을 대치한 데이터 생성
        - 2단계-분석단계 : 복수 개의 데이터셋에 대한 분석을 시행
        - 3단계-결합단계 : 복수 개의 분석결과에 대한 통계적 결합을 통해 결과 도출

### 03. 데이터 이상값 처리

1) 이상치

- 이상치란 데이터의 전처리 과정에 발생 가능한 문제로 정상의 범주(데이터의 전체적 패턴)에서 벗어난 값
- 데이터의 수집과정에서 오류가 발생할 수도 있기 매누에 이상치가 포함
- 오류가 아니더라도 굉장히 극단적인 값의 발생으로 인한 이상치가 존재할 수 있음
- 이상치는 앞선 결측치와 마찬가지로 분석결과의 왜곡이 발생할 수 있으므로 처리하는 작업 필요

2) 이상치의 종류 및 발생원인

- 이상치의 종류
    - 단변수 이상치 : 하나의 데이터 분포에서 발생하는 이상치
    - 다변수 이상치 : 복수의 연결된 데이터 분포공간에서 발생하는 이상치
- 이상치의 발생 원인
    - 비자연적 이상치 발생
        - 입력실수 : 데이터의 수집과정에서 발생하는 에러로 입력의 실수 등 지칭
        - 측정오류 : 데이터의 측정 중에 발생하는 에러로 측정기 고장(이상 작동)으로 발생되는 문제
        - 실험오류 : 실험과정 중 발생하는 에러로 실험환경에서 야기된 모든 문제점 지칭
        - 의도적 이상치 : 자기 보고 측정에서 발생되는 이상치
        - 자료처리오류 : 복수 개의 데이터셋에서 데이터를 추출, 조합하여 분석 시, 분석 전의 전처리에서 발생하는 에러
        - 표본오류 : 모집단에서 표본을 추출하는 과정에서 편향 발생
    - 상기 경우 이외에 발생하는 이상치들은 자연적 이상치

3) 이상치의 문제점

- 기초(통계적) 분석결과의 신뢰도 저하 : 평균, 분산 등에 영향, 단 중앙값은 영향이 적음
- 기초통계에 기반한 다른 고급 통계분석의 신뢰성 저하
    - 검정, 추정 등의 분석, 회귀분석 등이 영향
    - 특히 이상치가 비무작위성을 가지고 나타나게(분포하게) 되면 데이터의 정상성 감소를 초래하며 이는 데이터 자체의 신뢰성 저하로 연결될 가능성

4) 이상치의 탐지

- 종속변수가 단변량인지 다변량인지 데이터의 분포를 고려하여 모수적 또는 비모수적인지에 따라 다양한 방법으로 고려
- 시각화를 통한 방법(비모수적, 단변량의 경우)
    - 상자수염그림, 줄기-잎 그림
    -산점도 그림
- Z-Score 통한 방법 : 정규화를 통해 특정 threshold를 벗어난 경우를 이상치로 판별
- 밀도기반 클러스터링 방법 : 비모수적 다변량의 경우 군집간의 밀도를 이용하여 특정 거리 내의 데이터 수가 지정 개수 이상이면 군집으로 정의하는 방법, 정의된 군집에서 먼거리에 있는 데이터는 이상치로 간주
- 고립 의사나무 방법 : 비모수적 다변량의 경우 의사결정나무 기반으로 정상치의 단말 노드보다 이상치의 노드에 이르는 길이가 더 짧은 성질을 이용하는 방법 의미


## SECTION 02. 분석 변수 처리

### 01. 변수 선택

2) 변수별 모형의 분류

- 전체 모형 : 모든 독립변수를 사용한 모형으로 정의
- 축소 모형 : 전체 모형에서 사용된 변수의 개수를 줄여서 얻은 못형
- 영 모형 : 독립변수가 하나도 없는 모형

3) 변수의 선택 방법

- 전진 선택법
    - 영 모형에서 시작, 모든 독립변수 중 종속변수와 단순상관계수의 절댓값이 가장 큰 변수를 분석모형에 포함시키는 것
    - 부분 F 검정을 통해 유의성 검증을 시행, 유의한 경우는 가장 큰 F 통계량을 가지는 모형을 선택하고 유의하지 않은 경우는 변수선택 없이 과정 중단
    - 한번 추가된 변수는 제거하지 않는 것이 원칙
- 후진 선택법, 후진 소거법
    - 전체모델에서 시작, 모든 독립변수 중 종속변수와 단순상관계수의 절댓값이 가장 작은 변수를 분석모형에서 제외
    - 부분 F 검정을 통해 유의성 검증을 시행, 유의하지 않은 경우는 변수를 제거하고 유의한 경우는 변수제거 없이 과정 중단
    - 한번 제거된 변수는 추가하지 않음
- 단계적 선택법
    - 전진 선택법과 후진 선택법의 보완방법
    - 전진 선택법을 통해 가장 유의한 변수를 모형에 포함 후 나머지 변수들에 대해 후진 선택법을 적용하여 새롭게 유의하지 않은 변수들 제거
    - 제거된 변수는 다시 모형에 포함되지 않으며 유의한 설명변수가 존재하지 않을 때까지 과정 반복

### 02. 차원 축소

1) 자료의 차원 : 분석하는 데이터의 종류의 수

2) 차원의 축소 : 어떤 목적에 따라서 변수(데이터의 종류)의 양을 줄이는 것

3) 차원 축소의 필요성

- 복잡도의 축소 : 데이터를 분석하는 데 있어서 분석시간의 증가와 저장변수 양의 증가를 고려 시 동일한 품질을 나타낼 수 있다면 효율성 측면에서 데이터 종류의 수를 줄여야 함
- 과적합 방지
    - 차원의 증가는 분석모델 파라메터의 증가 및 파라메터 간의 복잡한 관계의 증가로 분석결과의 과적합 발생의 가능성이 커짐, 이것은 분석모형의 정확도(신뢰도) 저하를 발생
    - 작은 차원만으로 안정적인 결과를 도출해 낼 수 있다면 많은 차원을 다루는 것보다 효율적
- 해석력의 확보
    - 차원이 작은 간단한 분석모델일수록 내부구조 이해가 용이하고 해석이 쉬워짐
    - 해석이 쉬워지면 명확한 결과 도출에 많은 도움
- 차원의 저주
    - 데이터 분석 및 알고리즘을 통한 학습을 위해 차원이 증가하면서 학습데이터의 수가 차원의 수보다 적어져 성능 저하 현상
    - 해결을 위해서 차원을 줄이거나 데이터의 수를 늘리는 방법 이용

4) 차원 축소의 방법 : 데이터분석에 있어서 차원 축소의 피룡성을 인지하고 실제적으로 차원을 축소하는 데 사용될 수 있는 방법

- 요인 분석
    - 개념 : 다수의 변수들 간의 관계(상관관계)를 분석하여 공통차원을 축약하는 통계분석 과정
    - 목적
        - 변수 축소 : 다수의 변수들의 정보손실을 억제하면서 소수의 요인으로 축약
        - 변수 제거 : 요인에 대한 중요도 파악
        - 변수특성 파악 : 관련된 변수들이 묶임(군집)으로써 요인 간의 상호 독립성 파악 용이
        - 타당성 평가 : 묶여지지 않는 변수의 독립성 여부 판단
        - 파생변수 : 요인점수를 이용한 새로운 변수 생성, 회귀분석, 판별분석 및 군집분석 등에 이용
    - 특징 : 독립변수, 종속변수 개념이 없음, 주로 기술 통계에 의한 방법 이용
    - 종류
        - 주성분 분석, 공통요인 분석 특이값 분해 행렬, 음수미포함 행렬분해 등
        - 공통요인 분석은 분석대상 변수들이 기저를 이루는 구조를 정의하기 위한 요인분석 방법으로 변수들이 가지고 있는 공통분산만을 이용하여 공통요인만 추출하는 방법
- 주성분 분석
    - 개념
        - 분포된 데이터들의 특성을 설명할 수 있는 하나 또는 복수 개의 특징(주성분)을 찾는 것
        - 서로 연관성이 있는 고차원공간의 데이터를 선형연관성이 없는 저차원(주성분)으로 변환하는 과정(직교변환 사용)
        - 기존의 기본변수들을 새로운 변수의 세트로 변환하여 차원을 줄이되 기존 변수들의 분포특성을 최대한 보존하여 이를 통한 분석결과의 신뢰성 확보
    - PCA 방법의 이해
        - 2차원 좌표평면 n개의 점 데이터 (x1, y1), (x2, y2) ... (xn, yn) 들이 타원형으로 분포되어 있을때, 이 데이터들의 분포 특성을 2개의 벡터로 가장 잘 설명 할 수 있는 방법은 v1, v2 두 개의 벡터로 데이터분포를 설명하는 것
        - v1의 방향과 크기, 그리고 v2의 방향과 크기를 알면 이 데이터분포가 어떤 형태인지를 가장 단순하면서도 효과적으로 팡가 가능
        - PCA는 데이터 하나하나에 대한 성분을 분석하는 것이 아니라, 여러 데이터들이 모여 하나의 분포를 이룰 때, 이 분포의 주성분을 분석해 주는 바업
    - PCA의 특징
        - 차원 축소에 폭넓게 사용, 어떠한 사전적 분포 가정의 요구 없음
        - 가장 큰 분산의 방향들이 주요 중심 관심으로 가정
        - 본래의 변수들의 선형결합으로만 고려
        - 차원의 축소는 본래의 변수들이 서로 상관 있을 때만 가능
        - 스케일에 대한 영향이 큼, 즉 PCA 수행을 위해선 변수들 간의 스케일링 필수
- 특이값 분해
    - 특이값 분해 소개(선형대수)
        - 데이터공간을 나타내느 m × n 크기의 행렬 M에 대해, 다음과 같이 분해 가능
        - 여기서 U는 m × m 크기의 직교행렬이고 sigma는 m × n 크기의 대각행렬, Vt는 n × n 크기의 직교행렬
        - 직교행렬 : 행렬의 열벡터가 독립이라는 의미로 다음과 같은 관계 성립
        - 대각행렬 : 행렬의 대각성분을 제외한 나머지행렬의 원소의 값이 모두 0인 행렬
    - 특이값 분해의 차원 축소 원리
        - 수학적 원리 : SVD 방법은 주어진 행렬 M을 여러 개의 행렬 M과 동일한 크기를 갖는 행렬로 분해할 수 있으며 각 행렬의 원소값의 크기는 Diagonal Matrix에서 대각성분의 크기에 의해 결정
        - 데이터의 응용 : 기존의 전차원의 정보 A를 SVD에 의해서 3개의 행렬로 분해하면 적당한 k(특이값)만을 이용해 원래 행렬 A와 비슷한 정보력을 가지는 차원을 만들어 낼 수 있음
        - 큰 몇 개의 특이값을 가지고도 충분히 유용한 정보를 유지할 수 있는 차원을 생성해 낼 수 있음(차원 축소)
- 음수 미포함 행렬분해
    - 음수 미포함 행렬분해는 음수를 포함하지 않은 행렬 V를 음수를 포함하지 않은 두 행렬의 곱으로 분해하는 알고리즘
    - NMF의 이해
        - 일반적으로 W의 열 개수와 H의 행 개수가 WH=V가 되도록 결정, 기존 행렬 V와 분해한 음수 미포함 행렬 W와 H의 곱과의 차이를 오차 U라고 이야기 함, VV=WH+U, U의 원소들은 양수나 음수가 될 수 있음
        - W와 H의 크기가 V보다 작기 때문에 저장하거나 다루기에 용이, V를 원래 정보보다 상대적으로 적은 정보로 표현하여 분해한 행렬 하나가 전체 정보의 대략적인 정보 제시
    - NMF의 차원 축소 : 해열ㄹ 곱셈에서 곱해지는 행렬은 결과행렬보다 훨씬 적은 차원을 가지기 때문에 NMF가 차원 축소 가능

### 03. 파생변수의 생성

1) 파생변수

- 사용자가 특정 조건을 만족하거나 특정 함수에 의해 값을 만들어 의미를 부여하는 변수로 매우 주관적일 수 있으므로 논리적 타당성을 갖출 필요가 있음
- 세분화 고객행동예측, 캠페인반응예측 등에 활용
- 특정상황에만 유의미하지 않게 대표성을 나타나게 할 필요가 있음

2) 요약변수

- 수집된 정보를 분석에 맞게 종합한 변수
- 데이터 마트에서 가장 기본적인 변수
- 많은 분석 모델에서 공통으로 사용될 수 있어 재활용성이 높음

3) 요약변수 vs 파생변수

- 요약변수 처리시의 유의점
    - 처리 방법에 따라 결측치의 처리 및 이상값 처리에 유의
    - 연속형 변수의 구간화 적용과 고정된 구간화를 통한 의미 파악 시 정구간이 아닌 의미 있는 구간을 찾도록 해야 함
- 파생변수 생성 및 처리의 유의점
    - 특정 상황에만 의미성 부여가 아닌 보편적이고 전 데이터구간에 대표성을 가지는 파생변수 생성을 위해서 노력
    - 파생변수의 생성방법
        - 한 값으로부터 특징 추출
        - 한 레코드내의 값들 결합
        - 다른 테이블의 부가적 정보 결합
        - 다수의 필드내엣 시간 종속적인 데이터 선택
        - 레코드 또는 중요 필드 요약

### 04. 변수 변환

1) 개념

- 데이터를 분석하기 좋은 형태로 바꾸는 작업, 수학적 의미로 변환은 기존의 변수공간에서는 해결하거나 관찰할 수 없는 사실을 영역을 달리 하는 것으로(변환) 해석이 용이해지거나 취급이 단순해지는 장점
- 데이터의 전처리 과정 중 하나로 간주

2) 방법

- 범주형 변환 : 연속형 변수 중에서 변수자체로의 분석보다는 분석결과의 명료성 및 정확성을 배가시키기 위해 범주형으로 바꾸는 것이 좋은 경우가 있음
- 정규화
    - 분석을 정확히 하려면 원래 주어진 연속형(이산형) 데이터 값을 바로 사용하기 보다는 정규화를 이용하는 경우가 타당할 수 있음
    - 데이터가 가진 스케일이 심하게 차이나는 경우 그 차이를 그대로 반영하기 보다는 상대적 특성이 반영된 데이터로 변환하는 것이 필요
    - 일반 정규화 : 수치로 된 값들을 여러 개 사용할 때 각 수치의 범위가 다르면 이를 같은 범위로 변환해서 사용하는 것
    - 최소-최대 정규화
        - 데이터를 정규화하는 가장 일반적인 방법
        - 모든 feature에 대해 최소값 0, 최대값 1로, 그리고 다른 값들은 0과 1 사이의 값으로 변환하는 것
        - 만약 X라는 값에 대해 최소-최대 정규화를 한다면 다음과 같은 수식 사용 : (X - min) / (max - min)
        - 단점으로 이상치 영향을 많이 받는 점에 유의
    - Z-점수 정규화
        - 이상치 문제를 피하는 데이터 정규화 전략 : Z = (X - average) / sigma
        - 만약 데이터의 값이 평균과 일치하면 0으로 정규화되고, 평균보다 작으면 음수, 평균보다는 크면 양수로 나타남, 이 때 계산되는 음수와 양수의 크기는 데이터의 표준편차에 의해 결정, 그래서 만약 데이터의 표준편차가 크면 정규화되는 값이 0에 가까워짐
        - 이상치를 잘 처리하면, 정확히 동일한 척도로 정규화된 데이터를 생성하지는 않는다는 점에 유의
- 로그변환
    - 어떤 수치 값을 그대로 사용하지 않고 여기에 로그를 취한 값을 사용한 것 : X ~ ln(X)
    - 데이터 분석에서 로그를 취하는 게 타당한 경우가 종종 있는데 먼저 로그를 취하면 그 분포가 정규 분포에 가깝게 분포하는 경우가 있음
    - 로그변환분포를 사용하는 전형적 데이터
        - 국가별 수출액, 사람의 통증 정도 수치화, 개별 주식의 가격이용 변동성 분석 등
        - 데이터분포의 형태가 우측으로 치우친 경우 정규분포화를 위해 로그변환 사용
- 역수변환
    - 어떤변수를 데이터 분석에 그대로 사용하지 않고 역수를 사용하면 오히려 선형적인 특성을 가지게 되어 의미를 해석하기 쉬워지는 경우
    - 데이터분포의 형태를 보면 극단적은 우측으로 치우친 경우 정규분포화를 위해 역수변환 사용 : X ~ 1/X
- 지수변환
    - 어떤 변수를 데이터 분석에 그대로 사용하지 않고 지수를 사용하면 오히려 선형적인 특성을 가지게 되어 의미를 해석하기가 쉬워지는 경우
    - 데이터의 분포형태가 좌측으로 치우친 경우 정규분포화를 위해 지수변환 사용 : X ~ X ^ n
- 제곱근변환
    - 어떤 변수를 데이터 분석에 그대로 사용하지 않고 제곱근을 사용하면 오히려 선형적인 특성을 가지게 되어 의미를 해석하기 쉬워지는 경우
    - 데이터분포의 형태를 보면 우측으로 약간 치우친 경우 정규분포화를 위해 제곱근변환 사용 : X ~ root(X)

### 05. 불균형 데이터 처리

1) 불균형 데이터 : 어떤 데이터에서 각 클래스(주로 범주형 반응 변수)가 갖고 있는 데이터의 양에 차이가 큰 경우, 클래스 불균형이 있음

2) 문제점

- 데이터 클래스 비율이 너무 차이가 나면 단순히 우세한 클래스를 택하는 모형의 정확도가 높아지므로 모형의 성능판별이 어려워짐
- 정확도가 높아도 데이터 개수가 적은 클래스의 재현율이 급격히 작아지는 현상 발생

2) 처리 방법

- 가중치 균형방법 : 데이터에서 손실을 계산할 때 특정 클래스의 데이터에 더 큰 loss 값을 갖도록 하는 방법, 데이터 클래스의 균형이 필요한 경우로 각 클래스별 특정 비율로 가중치를 주어서 분석하거나 결과를 도출하는 것으로 정의
    - 고정 비율 이용 : 클래스의 비율에 따라 가중치를 두는 방법
    - 최적 비율 이용 : 분야와 최종 성능을 고려해 가중치 비율의 최적 세팅을 찾으면서 가중치를 찾아가는 방법
- 언더샘플링과 오버샘플링
    - 언더샘플링 : 대표클래스의 일부만을 선택하고, 소수클래스는 최대한 많은 데이터를 사용하는 방법, 언더샘플링된 대표클래스 데이터가 원본 데이터와 비교해 대표성이 있어야 함
    - 오버샘플링 : 소수클래스의 복사본을 만들어, 대표클래스의 수만큼 데이터를 만들어 주는 것, 똑같은 데이터를 그대로 복사하는 것이기 때문에 새로운 데이터는 기존 데이터와 같은 성질을 갖게 됨